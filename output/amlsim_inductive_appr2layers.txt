DATASET: amlsim
Epoch: 0001 train_loss= 0.68251 train_acc= 0.99609 val_loss= 0.63684 val_acc= 1.00000 time= 507.13292
Epoch: 0002 train_loss= 0.68246 train_acc= 1.00000 val_loss= 0.63899 val_acc= 1.00000 time= 502.54608
Epoch: 0003 train_loss= 0.67980 train_acc= 1.00000 val_loss= 0.64044 val_acc= 1.00000 time= 502.35562
Epoch: 0004 train_loss= 0.68243 train_acc= 1.00000 val_loss= 0.63540 val_acc= 1.00000 time= 518.02473
Epoch: 0005 train_loss= 0.68514 train_acc= 1.00000 val_loss= 0.64951 val_acc= 1.00000 time= 503.06029
Epoch: 0006 train_loss= 0.68240 train_acc= 1.00000 val_loss= 0.63550 val_acc= 1.00000 time= 502.95729
Epoch: 0007 train_loss= 0.68245 train_acc= 0.99609 val_loss= 0.64613 val_acc= 1.00000 time= 505.16650
Epoch: 0008 train_loss= 0.67970 train_acc= 1.00000 val_loss= 0.63633 val_acc= 1.00000 time= 503.99624
Epoch: 0009 train_loss= 0.68509 train_acc= 1.00000 val_loss= 0.64144 val_acc= 1.00000 time= 498.87764
Epoch: 0010 train_loss= 0.68507 train_acc= 1.00000 val_loss= 0.63709 val_acc= 1.00000 time= 500.57940
Epoch: 0011 train_loss= 0.68248 train_acc= 1.00000 val_loss= 0.65218 val_acc= 1.00000 time= 499.47761
Epoch: 0012 train_loss= 0.68512 train_acc= 1.00000 val_loss= 0.65468 val_acc= 1.00000 time= 503.71453
Epoch: 0013 train_loss= 0.68505 train_acc= 0.99219 val_loss= 0.64407 val_acc= 1.00000 time= 501.21105
Epoch: 0014 train_loss= 0.68251 train_acc= 0.99609 val_loss= 0.65351 val_acc= 1.00000 time= 501.98624
Epoch: 0015 train_loss= 0.68776 train_acc= 1.00000 val_loss= 0.64161 val_acc= 1.00000 time= 502.07612
Epoch: 0016 train_loss= 0.68506 train_acc= 0.98828 val_loss= 0.64476 val_acc= 1.00000 time= 501.67934
Epoch: 0017 train_loss= 0.68774 train_acc= 0.99219 val_loss= 0.65308 val_acc= 1.00000 time= 501.44681
Epoch: 0018 train_loss= 0.68774 train_acc= 0.99219 val_loss= 0.64665 val_acc= 1.00000 time= 500.06188
Epoch: 0019 train_loss= 0.68504 train_acc= 0.99609 val_loss= 0.63368 val_acc= 1.00000 time= 501.51386
Epoch: 0020 train_loss= 0.68235 train_acc= 1.00000 val_loss= 0.63440 val_acc= 1.00000 time= 501.71512
Epoch: 0021 train_loss= 0.67979 train_acc= 0.99609 val_loss= 0.64790 val_acc= 1.00000 time= 501.19530
Epoch: 0022 train_loss= 0.68508 train_acc= 0.99609 val_loss= 0.64441 val_acc= 1.00000 time= 502.21242
Epoch: 0023 train_loss= 0.68776 train_acc= 0.98438 val_loss= 0.64247 val_acc= 1.00000 time= 500.81337
Epoch: 0024 train_loss= 0.67990 train_acc= 0.99219 val_loss= 0.64619 val_acc= 1.00000 time= 499.87175
Epoch: 0025 train_loss= 0.68247 train_acc= 0.99219 val_loss= 0.65065 val_acc= 1.00000 time= 499.63769
Epoch: 0026 train_loss= 0.68506 train_acc= 0.99219 val_loss= 0.64001 val_acc= 1.00000 time= 501.32138
Epoch: 0027 train_loss= 0.68513 train_acc= 0.99609 val_loss= 0.65674 val_acc= 1.00000 time= 500.26031
Epoch: 0028 train_loss= 0.68774 train_acc= 0.99609 val_loss= 0.64052 val_acc= 1.00000 time= 499.11082
Epoch: 0029 train_loss= 0.68508 train_acc= 1.00000 val_loss= 0.64379 val_acc= 1.00000 time= 498.99034
Epoch: 0030 train_loss= 0.68238 train_acc= 0.99219 val_loss= 0.64144 val_acc= 1.00000 time= 499.66987
Epoch: 0031 train_loss= 0.68235 train_acc= 0.99219 val_loss= 0.63363 val_acc= 1.00000 time= 500.05176
Epoch: 0032 train_loss= 0.68242 train_acc= 0.98438 val_loss= 0.64695 val_acc= 1.00000 time= 498.84293
rank1 = 5 rank0 = 5 cost= 0.64732 accuracy= 0.99607 training time per epoch= 518.11485
F1-Score of non-Frauds: 0.998029
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499015
Epoch: 0001 train_loss= 0.67706 train_acc= 0.99609 val_loss= 0.60044 val_acc= 1.00000 time= 497.52096
Epoch: 0002 train_loss= 0.67703 train_acc= 1.00000 val_loss= 0.59801 val_acc= 1.00000 time= 497.72315
Epoch: 0003 train_loss= 0.67443 train_acc= 1.00000 val_loss= 0.60928 val_acc= 1.00000 time= 498.36517
Epoch: 0004 train_loss= 0.67700 train_acc= 0.99609 val_loss= 0.58820 val_acc= 1.00000 time= 499.61604
Epoch: 0005 train_loss= 0.67166 train_acc= 1.00000 val_loss= 0.60071 val_acc= 1.00000 time= 499.61853
Epoch: 0006 train_loss= 0.67726 train_acc= 0.99609 val_loss= 0.61501 val_acc= 1.00000 time= 497.72310
Epoch: 0007 train_loss= 0.67169 train_acc= 1.00000 val_loss= 0.60161 val_acc= 1.00000 time= 498.37696
Epoch: 0008 train_loss= 0.67427 train_acc= 0.99609 val_loss= 0.58648 val_acc= 1.00000 time= 500.04091
Epoch: 0009 train_loss= 0.67172 train_acc= 1.00000 val_loss= 0.60384 val_acc= 1.00000 time= 500.65612
Epoch: 0010 train_loss= 0.67966 train_acc= 0.98828 val_loss= 0.60371 val_acc= 1.00000 time= 502.44962
Epoch: 0011 train_loss= 0.67968 train_acc= 0.99609 val_loss= 0.59893 val_acc= 1.00000 time= 498.16394
Epoch: 0012 train_loss= 0.67697 train_acc= 0.99609 val_loss= 0.59478 val_acc= 1.00000 time= 498.88917
Epoch: 0013 train_loss= 0.67467 train_acc= 0.99219 val_loss= 0.62186 val_acc= 1.00000 time= 498.35756
Epoch: 0014 train_loss= 0.67695 train_acc= 0.99219 val_loss= 0.57990 val_acc= 1.00000 time= 498.98001
Epoch: 0015 train_loss= 0.67437 train_acc= 1.00000 val_loss= 0.60740 val_acc= 1.00000 time= 502.17904
Epoch: 0016 train_loss= 0.67434 train_acc= 0.99609 val_loss= 0.61384 val_acc= 1.00000 time= 502.30418
Epoch: 0017 train_loss= 0.67182 train_acc= 1.00000 val_loss= 0.61181 val_acc= 1.00000 time= 502.18956
Epoch: 0018 train_loss= 0.67183 train_acc= 1.00000 val_loss= 0.60003 val_acc= 1.00000 time= 502.44824
Epoch: 0019 train_loss= 0.67427 train_acc= 1.00000 val_loss= 0.58885 val_acc= 1.00000 time= 499.12621
Epoch: 0020 train_loss= 0.67430 train_acc= 0.99219 val_loss= 0.59689 val_acc= 1.00000 time= 499.22283
Epoch: 0021 train_loss= 0.67440 train_acc= 0.98828 val_loss= 0.60079 val_acc= 1.00000 time= 498.98813
Epoch: 0022 train_loss= 0.67695 train_acc= 0.99609 val_loss= 0.59351 val_acc= 1.00000 time= 499.45072
Epoch: 0023 train_loss= 0.67698 train_acc= 0.99609 val_loss= 0.59422 val_acc= 1.00000 time= 501.88313
Epoch: 0024 train_loss= 0.67422 train_acc= 0.99609 val_loss= 0.56526 val_acc= 1.00000 time= 501.92531
Epoch: 0025 train_loss= 0.67424 train_acc= 1.00000 val_loss= 0.58093 val_acc= 1.00000 time= 501.63061
Epoch: 0026 train_loss= 0.67967 train_acc= 1.00000 val_loss= 0.59991 val_acc= 1.00000 time= 502.01292
Epoch: 0027 train_loss= 0.67700 train_acc= 1.00000 val_loss= 0.60033 val_acc= 1.00000 time= 498.58832
Epoch: 0028 train_loss= 0.67449 train_acc= 1.00000 val_loss= 0.61491 val_acc= 1.00000 time= 499.11097
Epoch: 0029 train_loss= 0.66901 train_acc= 1.00000 val_loss= 0.60051 val_acc= 1.00000 time= 498.41244
Epoch: 0030 train_loss= 0.67431 train_acc= 0.99609 val_loss= 0.60029 val_acc= 1.00000 time= 499.19751
Epoch: 0031 train_loss= 0.67705 train_acc= 0.99219 val_loss= 0.60420 val_acc= 1.00000 time= 502.52988
Epoch: 0032 train_loss= 0.67976 train_acc= 0.99219 val_loss= 0.60974 val_acc= 1.00000 time= 502.44745
rank1 = 10 rank0 = 10 cost= 0.61043 accuracy= 0.99607 training time per epoch= 516.13328
F1-Score of non-Frauds: 0.998029
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499015
Epoch: 0001 train_loss= 0.65562 train_acc= 0.99609 val_loss= 0.47717 val_acc= 1.00000 time= 498.62575
Epoch: 0002 train_loss= 0.64492 train_acc= 0.99609 val_loss= 0.48108 val_acc= 1.00000 time= 497.52904
Epoch: 0003 train_loss= 0.65822 train_acc= 0.99609 val_loss= 0.48167 val_acc= 1.00000 time= 498.48537
Epoch: 0004 train_loss= 0.65311 train_acc= 0.99609 val_loss= 0.49699 val_acc= 1.00000 time= 497.93235
Epoch: 0005 train_loss= 0.65293 train_acc= 0.99609 val_loss= 0.46585 val_acc= 1.00000 time= 498.00543
Epoch: 0006 train_loss= 0.65292 train_acc= 1.00000 val_loss= 0.49892 val_acc= 1.00000 time= 499.51249
Epoch: 0007 train_loss= 0.64753 train_acc= 1.00000 val_loss= 0.46674 val_acc= 1.00000 time= 499.72183
Epoch: 0008 train_loss= 0.64485 train_acc= 0.99219 val_loss= 0.47918 val_acc= 1.00000 time= 499.44530
Epoch: 0009 train_loss= 0.65279 train_acc= 0.98828 val_loss= 0.49029 val_acc= 1.00000 time= 503.46409
Epoch: 0010 train_loss= 0.65578 train_acc= 1.00000 val_loss= 0.51497 val_acc= 1.00000 time= 501.43111
Epoch: 0011 train_loss= 0.65289 train_acc= 0.99609 val_loss= 0.48666 val_acc= 1.00000 time= 497.23302
Epoch: 0012 train_loss= 0.64513 train_acc= 0.99219 val_loss= 0.48950 val_acc= 1.00000 time= 496.40632
Epoch: 0013 train_loss= 0.65034 train_acc= 0.99609 val_loss= 0.50070 val_acc= 1.00000 time= 496.59217
Epoch: 0014 train_loss= 0.65012 train_acc= 0.99219 val_loss= 0.47609 val_acc= 1.00000 time= 496.94779
Epoch: 0015 train_loss= 0.65014 train_acc= 1.00000 val_loss= 0.48136 val_acc= 1.00000 time= 498.24105
Epoch: 0016 train_loss= 0.65015 train_acc= 0.99219 val_loss= 0.49628 val_acc= 1.00000 time= 497.89427
Epoch: 0017 train_loss= 0.65020 train_acc= 1.00000 val_loss= 0.49095 val_acc= 1.00000 time= 518.32416
Epoch: 0018 train_loss= 0.64782 train_acc= 1.00000 val_loss= 0.50241 val_acc= 1.00000 time= 498.06527
Epoch: 0019 train_loss= 0.65022 train_acc= 0.99609 val_loss= 0.48640 val_acc= 1.00000 time= 502.54972
Epoch: 0020 train_loss= 0.64753 train_acc= 0.99219 val_loss= 0.48946 val_acc= 1.00000 time= 497.74490
Epoch: 0021 train_loss= 0.65047 train_acc= 1.00000 val_loss= 0.49526 val_acc= 1.00000 time= 498.45305
Epoch: 0022 train_loss= 0.65540 train_acc= 0.99609 val_loss= 0.47511 val_acc= 1.00000 time= 499.12747
Epoch: 0023 train_loss= 0.64752 train_acc= 1.00000 val_loss= 0.48522 val_acc= 1.00000 time= 505.26965
Epoch: 0024 train_loss= 0.65822 train_acc= 0.98828 val_loss= 0.50406 val_acc= 1.00000 time= 504.05495
Epoch: 0025 train_loss= 0.65004 train_acc= 0.99219 val_loss= 0.47149 val_acc= 1.00000 time= 501.29268
Epoch: 0026 train_loss= 0.65026 train_acc= 1.00000 val_loss= 0.49890 val_acc= 1.00000 time= 502.79555
Epoch: 0027 train_loss= 0.65632 train_acc= 1.00000 val_loss= 0.49060 val_acc= 1.00000 time= 503.84595
Epoch: 0028 train_loss= 0.65285 train_acc= 0.99219 val_loss= 0.49044 val_acc= 1.00000 time= 503.69047
Epoch: 0029 train_loss= 0.65554 train_acc= 1.00000 val_loss= 0.48873 val_acc= 1.00000 time= 501.61652
Epoch: 0030 train_loss= 0.65282 train_acc= 0.99219 val_loss= 0.47060 val_acc= 1.00000 time= 500.72880
Epoch: 0031 train_loss= 0.65282 train_acc= 1.00000 val_loss= 0.48449 val_acc= 1.00000 time= 524.78469
Epoch: 0032 train_loss= 0.65549 train_acc= 0.99219 val_loss= 0.50002 val_acc= 1.00000 time= 500.80418
rank1 = 25 rank0 = 25 cost= 0.50172 accuracy= 0.99607 training time per epoch= 517.43932
F1-Score of non-Frauds: 0.998029
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499015
Epoch: 0001 train_loss= 0.68009 train_acc= 0.99609 val_loss= 0.33354 val_acc= 1.00000 time= 506.35140
Epoch: 0002 train_loss= 0.60790 train_acc= 1.00000 val_loss= 0.34882 val_acc= 1.00000 time= 502.37568
Epoch: 0003 train_loss= 0.61553 train_acc= 0.99609 val_loss= 0.34899 val_acc= 1.00000 time= 501.62121
Epoch: 0004 train_loss= 0.60787 train_acc= 1.00000 val_loss= 0.33800 val_acc= 1.00000 time= 501.53154
Epoch: 0005 train_loss= 0.60459 train_acc= 0.99609 val_loss= 0.32633 val_acc= 1.00000 time= 501.97600
Epoch: 0006 train_loss= 0.61011 train_acc= 1.00000 val_loss= 0.34469 val_acc= 1.00000 time= 506.37422
Epoch: 0007 train_loss= 0.61559 train_acc= 0.98828 val_loss= 0.34880 val_acc= 1.00000 time= 508.99022
Epoch: 0008 train_loss= 0.60559 train_acc= 1.00000 val_loss= 0.33570 val_acc= 1.00000 time= 510.19104
Epoch: 0009 train_loss= 0.60465 train_acc= 0.99609 val_loss= 0.32628 val_acc= 1.00000 time= 505.19801
Epoch: 0010 train_loss= 0.61295 train_acc= 1.00000 val_loss= 0.35195 val_acc= 1.00000 time= 509.47642
Epoch: 0011 train_loss= 0.60209 train_acc= 0.99609 val_loss= 0.31970 val_acc= 1.00000 time= 505.18342
Epoch: 0012 train_loss= 0.65687 train_acc= 0.99219 val_loss= 0.36444 val_acc= 1.00000 time= 508.87655
Epoch: 0013 train_loss= 0.60457 train_acc= 0.99609 val_loss= 0.32655 val_acc= 1.00000 time= 507.29862
Epoch: 0014 train_loss= 0.60777 train_acc= 0.99609 val_loss= 0.34003 val_acc= 1.00000 time= 509.29264
Epoch: 0015 train_loss= 0.62945 train_acc= 0.98828 val_loss= 0.35024 val_acc= 1.00000 time= 507.49523
Epoch: 0016 train_loss= 0.60985 train_acc= 1.00000 val_loss= 0.32178 val_acc= 1.00000 time= 511.51107
Epoch: 0017 train_loss= 0.60706 train_acc= 1.00000 val_loss= 0.31223 val_acc= 1.00000 time= 507.75338
Epoch: 0018 train_loss= 0.61006 train_acc= 0.99219 val_loss= 0.33414 val_acc= 1.00000 time= 511.44299
Epoch: 0019 train_loss= 0.60513 train_acc= 0.99609 val_loss= 0.31528 val_acc= 1.00000 time= 509.61380
Epoch: 0020 train_loss= 0.60994 train_acc= 0.99609 val_loss= 0.33999 val_acc= 1.00000 time= 512.05337
Epoch: 0021 train_loss= 0.61252 train_acc= 0.99609 val_loss= 0.30274 val_acc= 1.00000 time= 511.38804
Epoch: 0022 train_loss= 0.60220 train_acc= 0.99609 val_loss= 0.33236 val_acc= 1.00000 time= 510.62879
Epoch: 0023 train_loss= 0.60464 train_acc= 0.99219 val_loss= 0.32008 val_acc= 1.00000 time= 505.87329
Epoch: 0024 train_loss= 0.59928 train_acc= 0.98828 val_loss= 0.32464 val_acc= 1.00000 time= 510.41182
Epoch: 0025 train_loss= 0.61769 train_acc= 0.99609 val_loss= 0.29854 val_acc= 1.00000 time= 509.10974
Epoch: 0026 train_loss= 0.60741 train_acc= 0.99609 val_loss= 0.33720 val_acc= 1.00000 time= 508.91412
Epoch: 0027 train_loss= 0.59901 train_acc= 1.00000 val_loss= 0.31114 val_acc= 1.00000 time= 505.61619
Epoch: 0028 train_loss= 0.61809 train_acc= 0.99609 val_loss= 0.34079 val_acc= 1.00000 time= 511.09111
Epoch: 0029 train_loss= 0.59660 train_acc= 0.99609 val_loss= 0.32209 val_acc= 1.00000 time= 509.75292
Epoch: 0030 train_loss= 0.59447 train_acc= 1.00000 val_loss= 0.34744 val_acc= 1.00000 time= 508.14582
Epoch: 0031 train_loss= 0.60262 train_acc= 1.00000 val_loss= 0.35634 val_acc= 1.00000 time= 509.84925
Epoch: 0032 train_loss= 0.61263 train_acc= 1.00000 val_loss= 0.33738 val_acc= 1.00000 time= 509.05447
rank1 = 50 rank0 = 50 cost= 0.34097 accuracy= 0.99607 training time per epoch= 524.33695
F1-Score of non-Frauds: 0.998029
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499015
