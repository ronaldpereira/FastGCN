DATASET: amlsim
Epoch: 0001 train_loss= 0.68526 train_acc= 0.99609 val_loss= 0.64021 val_acc= 1.00000 time= 510.32887
Epoch: 0002 train_loss= 0.68281 train_acc= 1.00000 val_loss= 0.65631 val_acc= 1.00000 time= 507.13988
Epoch: 0003 train_loss= 0.68517 train_acc= 1.00000 val_loss= 0.62463 val_acc= 1.00000 time= 510.71294
Epoch: 0004 train_loss= 0.68245 train_acc= 1.00000 val_loss= 0.63844 val_acc= 1.00000 time= 505.90472
Epoch: 0005 train_loss= 0.67971 train_acc= 1.00000 val_loss= 0.61774 val_acc= 1.00000 time= 505.75274
Epoch: 0006 train_loss= 0.68240 train_acc= 1.00000 val_loss= 0.63114 val_acc= 1.00000 time= 505.66413
Epoch: 0007 train_loss= 0.68779 train_acc= 0.99609 val_loss= 0.63616 val_acc= 1.00000 time= 505.19731
Epoch: 0008 train_loss= 0.68249 train_acc= 1.00000 val_loss= 0.64798 val_acc= 1.00000 time= 504.96726
Epoch: 0009 train_loss= 0.67966 train_acc= 1.00000 val_loss= 0.62210 val_acc= 1.00000 time= 503.03049
Epoch: 0010 train_loss= 0.68508 train_acc= 1.00000 val_loss= 0.63003 val_acc= 1.00000 time= 502.38662
Epoch: 0011 train_loss= 0.68507 train_acc= 1.00000 val_loss= 0.63445 val_acc= 1.00000 time= 502.20117
Epoch: 0012 train_loss= 0.68236 train_acc= 1.00000 val_loss= 0.62948 val_acc= 1.00000 time= 520.62060
Epoch: 0013 train_loss= 0.68238 train_acc= 0.99219 val_loss= 0.63576 val_acc= 1.00000 time= 500.95997
Epoch: 0014 train_loss= 0.68507 train_acc= 0.99609 val_loss= 0.64645 val_acc= 1.00000 time= 505.31185
Epoch: 0015 train_loss= 0.68515 train_acc= 1.00000 val_loss= 0.65104 val_acc= 1.00000 time= 500.88904
Epoch: 0016 train_loss= 0.68234 train_acc= 0.98828 val_loss= 0.63386 val_acc= 1.00000 time= 500.30481
Epoch: 0017 train_loss= 0.68235 train_acc= 0.99219 val_loss= 0.63643 val_acc= 1.00000 time= 500.42690
Epoch: 0018 train_loss= 0.68505 train_acc= 0.99219 val_loss= 0.64048 val_acc= 1.00000 time= 501.24951
Epoch: 0019 train_loss= 0.70362 train_acc= 0.99609 val_loss= 0.63252 val_acc= 1.00000 time= 500.26625
Epoch: 0020 train_loss= 0.68505 train_acc= 1.00000 val_loss= 0.64015 val_acc= 1.00000 time= 499.76710
Epoch: 0021 train_loss= 0.68271 train_acc= 0.99609 val_loss= 0.64155 val_acc= 1.00000 time= 500.41241
Epoch: 0022 train_loss= 0.68235 train_acc= 0.99609 val_loss= 0.63360 val_acc= 1.00000 time= 499.59652
Epoch: 0023 train_loss= 0.68251 train_acc= 0.98438 val_loss= 0.65020 val_acc= 1.00000 time= 500.00799
Epoch: 0024 train_loss= 0.68000 train_acc= 0.99219 val_loss= 0.64498 val_acc= 1.00000 time= 499.92790
Epoch: 0025 train_loss= 0.68242 train_acc= 0.99219 val_loss= 0.64073 val_acc= 1.00000 time= 500.12680
Epoch: 0026 train_loss= 0.68236 train_acc= 0.99219 val_loss= 0.63979 val_acc= 1.00000 time= 499.35301
Epoch: 0027 train_loss= 0.68504 train_acc= 0.99609 val_loss= 0.63429 val_acc= 1.00000 time= 500.09089
Epoch: 0028 train_loss= 0.67964 train_acc= 0.99609 val_loss= 0.63776 val_acc= 1.00000 time= 499.78803
Epoch: 0029 train_loss= 0.68237 train_acc= 1.00000 val_loss= 0.64004 val_acc= 1.00000 time= 504.34536
Epoch: 0030 train_loss= 0.68775 train_acc= 0.99219 val_loss= 0.64390 val_acc= 1.00000 time= 504.57642
Epoch: 0031 train_loss= 0.67699 train_acc= 0.99219 val_loss= 0.64118 val_acc= 1.00000 time= 500.72117
Epoch: 0032 train_loss= 0.67966 train_acc= 0.98438 val_loss= 0.63994 val_acc= 1.00000 time= 499.95333
rank1 = 5 rank0 = 5 cost= 0.63955 accuracy= 0.99607 training time per epoch= 519.41888
F1-Score of non-Frauds: 0.998029
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499015
Epoch: 0001 train_loss= 0.67183 train_acc= 0.99609 val_loss= 0.60637 val_acc= 1.00000 time= 507.76983
Epoch: 0002 train_loss= 0.67433 train_acc= 1.00000 val_loss= 0.59907 val_acc= 1.00000 time= 504.90454
Epoch: 0003 train_loss= 0.67973 train_acc= 1.00000 val_loss= 0.61476 val_acc= 1.00000 time= 505.25964
Epoch: 0004 train_loss= 0.67698 train_acc= 0.99609 val_loss= 0.58590 val_acc= 1.00000 time= 505.89530
Epoch: 0005 train_loss= 0.67474 train_acc= 1.00000 val_loss= 0.61593 val_acc= 1.00000 time= 507.56561
Epoch: 0006 train_loss= 0.67428 train_acc= 0.99609 val_loss= 0.58119 val_acc= 1.00000 time= 505.38258
Epoch: 0007 train_loss= 0.68235 train_acc= 1.00000 val_loss= 0.60552 val_acc= 1.00000 time= 505.06769
Epoch: 0008 train_loss= 0.67696 train_acc= 0.99609 val_loss= 0.58162 val_acc= 1.00000 time= 506.68606
Epoch: 0009 train_loss= 0.67697 train_acc= 1.00000 val_loss= 0.59685 val_acc= 1.00000 time= 505.67498
Epoch: 0010 train_loss= 0.67970 train_acc= 0.98828 val_loss= 0.60425 val_acc= 1.00000 time= 504.57438
Epoch: 0011 train_loss= 0.67703 train_acc= 0.99609 val_loss= 0.60503 val_acc= 1.00000 time= 502.38349
Epoch: 0012 train_loss= 0.67431 train_acc= 0.99609 val_loss= 0.57641 val_acc= 1.00000 time= 506.69854
Epoch: 0013 train_loss= 0.67168 train_acc= 0.99219 val_loss= 0.58838 val_acc= 1.00000 time= 504.63249
Epoch: 0014 train_loss= 0.67187 train_acc= 0.99219 val_loss= 0.60163 val_acc= 1.00000 time= 506.61694
Epoch: 0015 train_loss= 0.67983 train_acc= 1.00000 val_loss= 0.62121 val_acc= 1.00000 time= 506.64485
Epoch: 0016 train_loss= 0.67167 train_acc= 0.99609 val_loss= 0.59915 val_acc= 1.00000 time= 505.22443
Epoch: 0017 train_loss= 0.67969 train_acc= 1.00000 val_loss= 0.59547 val_acc= 1.00000 time= 506.37057
Epoch: 0018 train_loss= 0.67427 train_acc= 1.00000 val_loss= 0.59286 val_acc= 1.00000 time= 505.31898
Epoch: 0019 train_loss= 0.67516 train_acc= 1.00000 val_loss= 0.60703 val_acc= 1.00000 time= 505.54241
Epoch: 0020 train_loss= 0.67701 train_acc= 0.99219 val_loss= 0.60626 val_acc= 1.00000 time= 506.48408
Epoch: 0021 train_loss= 0.67448 train_acc= 0.98828 val_loss= 0.61314 val_acc= 1.00000 time= 505.12576
Epoch: 0022 train_loss= 0.67699 train_acc= 0.99609 val_loss= 0.59247 val_acc= 1.00000 time= 504.44773
Epoch: 0023 train_loss= 0.71417 train_acc= 0.99609 val_loss= 0.59910 val_acc= 1.00000 time= 502.09878
Epoch: 0024 train_loss= 0.67432 train_acc= 0.99609 val_loss= 0.59265 val_acc= 1.00000 time= 506.74664
Epoch: 0025 train_loss= 0.67184 train_acc= 1.00000 val_loss= 0.60313 val_acc= 1.00000 time= 504.84958
Epoch: 0026 train_loss= 0.66913 train_acc= 1.00000 val_loss= 0.59443 val_acc= 1.00000 time= 506.45246
Epoch: 0027 train_loss= 0.66894 train_acc= 1.00000 val_loss= 0.59732 val_acc= 1.00000 time= 506.34971
Epoch: 0028 train_loss= 0.67424 train_acc= 1.00000 val_loss= 0.58710 val_acc= 1.00000 time= 505.39504
Epoch: 0029 train_loss= 0.66932 train_acc= 1.00000 val_loss= 0.58846 val_acc= 1.00000 time= 506.43660
Epoch: 0030 train_loss= 0.67964 train_acc= 0.99609 val_loss= 0.59328 val_acc= 1.00000 time= 505.29325
Epoch: 0031 train_loss= 0.67695 train_acc= 0.99219 val_loss= 0.59170 val_acc= 1.00000 time= 505.38636
Epoch: 0032 train_loss= 0.67702 train_acc= 0.99219 val_loss= 0.60098 val_acc= 1.00000 time= 506.55650
rank1 = 10 rank0 = 10 cost= 0.60035 accuracy= 0.99607 training time per epoch= 521.93029
F1-Score of non-Frauds: 0.998029
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499015
Epoch: 0001 train_loss= 0.64209 train_acc= 0.99609 val_loss= 0.42671 val_acc= 1.00000 time= 524.05215
Epoch: 0002 train_loss= 0.65034 train_acc= 0.99609 val_loss= 0.44341 val_acc= 1.00000 time= 520.46260
Epoch: 0003 train_loss= 0.67192 train_acc= 0.99609 val_loss= 0.47825 val_acc= 1.00000 time= 517.83668
Epoch: 0004 train_loss= 0.65029 train_acc= 0.99609 val_loss= 0.47052 val_acc= 1.00000 time= 511.96931
Epoch: 0005 train_loss= 0.64497 train_acc= 0.99609 val_loss= 0.48721 val_acc= 1.00000 time= 507.47057
Epoch: 0006 train_loss= 0.65091 train_acc= 1.00000 val_loss= 0.48186 val_acc= 1.00000 time= 519.27390
Epoch: 0007 train_loss= 0.65003 train_acc= 1.00000 val_loss= 0.45262 val_acc= 1.00000 time= 500.83031
Epoch: 0008 train_loss= 0.64465 train_acc= 0.99219 val_loss= 0.46949 val_acc= 1.00000 time= 504.84044
Epoch: 0009 train_loss= 0.65268 train_acc= 0.98828 val_loss= 0.45556 val_acc= 1.00000 time= 511.20179
Epoch: 0010 train_loss= 0.63989 train_acc= 1.00000 val_loss= 0.47332 val_acc= 1.00000 time= 510.61085
Epoch: 0011 train_loss= 0.65548 train_acc= 0.99609 val_loss= 0.46927 val_acc= 1.00000 time= 517.21285
Epoch: 0012 train_loss= 0.65009 train_acc= 0.99219 val_loss= 0.46547 val_acc= 1.00000 time= 504.75677
Epoch: 0013 train_loss= 0.64757 train_acc= 0.99609 val_loss= 0.47540 val_acc= 1.00000 time= 503.81082
Epoch: 0014 train_loss= 0.65579 train_acc= 0.99219 val_loss= 0.48104 val_acc= 1.00000 time= 500.28312
Epoch: 0015 train_loss= 0.64479 train_acc= 1.00000 val_loss= 0.46739 val_acc= 1.00000 time= 504.77288
Epoch: 0016 train_loss= 0.65287 train_acc= 0.99219 val_loss= 0.47264 val_acc= 1.00000 time= 501.89319
Epoch: 0017 train_loss= 0.64782 train_acc= 1.00000 val_loss= 0.49477 val_acc= 1.00000 time= 519.32633
Epoch: 0018 train_loss= 0.64497 train_acc= 1.00000 val_loss= 0.46728 val_acc= 1.00000 time= 515.84071
Epoch: 0019 train_loss= 0.64774 train_acc= 0.99609 val_loss= 0.49130 val_acc= 1.00000 time= 510.74738
Epoch: 0020 train_loss= 0.71855 train_acc= 0.99219 val_loss= 0.47070 val_acc= 1.00000 time= 506.95413
Epoch: 0021 train_loss= 0.64481 train_acc= 1.00000 val_loss= 0.46148 val_acc= 1.00000 time= 509.43118
Epoch: 0022 train_loss= 0.64237 train_acc= 0.99609 val_loss= 0.47910 val_acc= 1.00000 time= 504.24708
Epoch: 0023 train_loss= 0.63940 train_acc= 1.00000 val_loss= 0.46772 val_acc= 1.00000 time= 500.93770
Epoch: 0024 train_loss= 0.64251 train_acc= 0.98828 val_loss= 0.46048 val_acc= 1.00000 time= 505.42062
Epoch: 0025 train_loss= 0.64744 train_acc= 0.99219 val_loss= 0.48678 val_acc= 1.00000 time= 499.99582
Epoch: 0026 train_loss= 0.65055 train_acc= 1.00000 val_loss= 0.49189 val_acc= 1.00000 time= 518.89608
Epoch: 0027 train_loss= 0.63936 train_acc= 1.00000 val_loss= 0.45495 val_acc= 1.00000 time= 505.40302
Epoch: 0028 train_loss= 0.64998 train_acc= 0.99219 val_loss= 0.47006 val_acc= 1.00000 time= 504.44404
Epoch: 0029 train_loss= 0.66888 train_acc= 1.00000 val_loss= 0.46568 val_acc= 1.00000 time= 518.98440
Epoch: 0030 train_loss= 0.65287 train_acc= 0.99219 val_loss= 0.46093 val_acc= 1.00000 time= 504.54378
Epoch: 0031 train_loss= 0.64524 train_acc= 1.00000 val_loss= 0.48403 val_acc= 1.00000 time= 503.56946
Epoch: 0032 train_loss= 0.64756 train_acc= 0.99219 val_loss= 0.48509 val_acc= 1.00000 time= 505.51281
rank1 = 25 rank0 = 25 cost= 0.48403 accuracy= 0.99607 training time per epoch= 525.66368
F1-Score of non-Frauds: 0.998029
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499015
Epoch: 0001 train_loss= 0.59440 train_acc= 0.99609 val_loss= 0.29309 val_acc= 1.00000 time= 516.44850
Epoch: 0002 train_loss= 0.61015 train_acc= 1.00000 val_loss= 0.31463 val_acc= 1.00000 time= 508.06472
Epoch: 0003 train_loss= 0.60220 train_acc= 0.99609 val_loss= 0.32060 val_acc= 1.00000 time= 507.86152
Epoch: 0004 train_loss= 0.60252 train_acc= 1.00000 val_loss= 0.30124 val_acc= 1.00000 time= 522.45009
Epoch: 0005 train_loss= 0.60191 train_acc= 0.99609 val_loss= 0.31528 val_acc= 1.00000 time= 506.58636
Epoch: 0006 train_loss= 0.60798 train_acc= 1.00000 val_loss= 0.30725 val_acc= 1.00000 time= 508.55787
Epoch: 0007 train_loss= 0.60233 train_acc= 0.98828 val_loss= 0.31165 val_acc= 1.00000 time= 514.99806
Epoch: 0008 train_loss= 0.60715 train_acc= 1.00000 val_loss= 0.28433 val_acc= 1.00000 time= 512.36520
Epoch: 0009 train_loss= 0.59172 train_acc= 0.99609 val_loss= 0.32309 val_acc= 1.00000 time= 511.87509
Epoch: 0010 train_loss= 0.61234 train_acc= 1.00000 val_loss= 0.29649 val_acc= 1.00000 time= 511.76542
Epoch: 0011 train_loss= 0.60005 train_acc= 0.99609 val_loss= 0.33178 val_acc= 1.00000 time= 507.80220
Epoch: 0012 train_loss= 0.60485 train_acc= 0.99219 val_loss= 0.35529 val_acc= 1.00000 time= 525.30436
Epoch: 0013 train_loss= 0.59945 train_acc= 0.99609 val_loss= 0.30774 val_acc= 1.00000 time= 510.22235
Epoch: 0014 train_loss= 0.61272 train_acc= 0.99609 val_loss= 0.32131 val_acc= 1.00000 time= 511.34331
Epoch: 0015 train_loss= 0.59987 train_acc= 0.98828 val_loss= 0.32420 val_acc= 1.00000 time= 507.63442
Epoch: 0016 train_loss= 0.59916 train_acc= 1.00000 val_loss= 0.31799 val_acc= 1.00000 time= 522.49718
Epoch: 0017 train_loss= 0.59712 train_acc= 1.00000 val_loss= 0.30938 val_acc= 1.00000 time= 510.65338
Epoch: 0018 train_loss= 0.59149 train_acc= 0.99219 val_loss= 0.30191 val_acc= 1.00000 time= 510.45494
Epoch: 0019 train_loss= 0.61007 train_acc= 0.99609 val_loss= 0.32580 val_acc= 1.00000 time= 506.68309
Epoch: 0020 train_loss= 0.62037 train_acc= 0.99609 val_loss= 0.30904 val_acc= 1.00000 time= 501.66560
Epoch: 0021 train_loss= 0.59183 train_acc= 0.99609 val_loss= 0.33308 val_acc= 1.00000 time= 502.89896
Epoch: 0022 train_loss= 0.59883 train_acc= 0.99609 val_loss= 0.30473 val_acc= 1.00000 time= 506.33232
Epoch: 0023 train_loss= 0.62193 train_acc= 0.99219 val_loss= 0.30118 val_acc= 1.00000 time= 521.75796
Epoch: 0024 train_loss= 0.59469 train_acc= 0.98828 val_loss= 0.31055 val_acc= 1.00000 time= 501.87649
Epoch: 0025 train_loss= 0.59214 train_acc= 0.99609 val_loss= 0.32513 val_acc= 1.00000 time= 511.74074
Epoch: 0026 train_loss= 0.59142 train_acc= 0.99609 val_loss= 0.30620 val_acc= 1.00000 time= 500.90850
Epoch: 0027 train_loss= 0.60291 train_acc= 1.00000 val_loss= 0.29757 val_acc= 1.00000 time= 519.41457
Epoch: 0028 train_loss= 0.66078 train_acc= 0.99609 val_loss= 0.33253 val_acc= 1.00000 time= 505.50781
Epoch: 0029 train_loss= 0.59709 train_acc= 0.99609 val_loss= 0.31560 val_acc= 1.00000 time= 503.24313
Epoch: 0030 train_loss= 0.60202 train_acc= 1.00000 val_loss= 0.31512 val_acc= 1.00000 time= 500.15945
Epoch: 0031 train_loss= 0.61226 train_acc= 1.00000 val_loss= 0.29508 val_acc= 1.00000 time= 503.05425
Epoch: 0032 train_loss= 0.58966 train_acc= 1.00000 val_loss= 0.31177 val_acc= 1.00000 time= 500.11587
Epoch: 0033 train_loss= 0.60084 train_acc= 0.99609 val_loss= 0.31237 val_acc= 1.00000 time= 500.16052
Epoch: 0034 train_loss= 0.59890 train_acc= 1.00000 val_loss= 0.29398 val_acc= 1.00000 time= 519.06461
Epoch: 0035 train_loss= 0.61515 train_acc= 1.00000 val_loss= 0.33711 val_acc= 1.00000 time= 502.15409
rank1 = 50 rank0 = 50 cost= 0.33642 accuracy= 0.99607 training time per epoch= 524.52039
F1-Score of non-Frauds: 0.998029
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499015
