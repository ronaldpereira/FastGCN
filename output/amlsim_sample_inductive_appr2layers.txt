DATASET: amlsim_sample
Epoch: 0001 train_loss= 0.68466 train_acc= 0.99609 val_loss= 0.56229 val_acc= 1.00000 time= 0.50479
Epoch: 0002 train_loss= 0.67885 train_acc= 1.00000 val_loss= 0.55685 val_acc= 1.00000 time= 0.42351
Epoch: 0003 train_loss= 0.67853 train_acc= 1.00000 val_loss= 0.55297 val_acc= 1.00000 time= 0.42406
Epoch: 0004 train_loss= 0.68908 train_acc= 1.00000 val_loss= 0.55210 val_acc= 1.00000 time= 0.42432
Epoch: 0005 train_loss= 0.68614 train_acc= 1.00000 val_loss= 0.55468 val_acc= 1.00000 time= 0.41387
Epoch: 0006 train_loss= 0.68594 train_acc= 1.00000 val_loss= 0.55679 val_acc= 1.00000 time= 0.42097
Epoch: 0007 train_loss= 0.68578 train_acc= 1.00000 val_loss= 0.55735 val_acc= 1.00000 time= 0.42007
Epoch: 0008 train_loss= 0.68835 train_acc= 1.00000 val_loss= 0.55252 val_acc= 1.00000 time= 0.40276
Epoch: 0009 train_loss= 0.68282 train_acc= 1.00000 val_loss= 0.55412 val_acc= 1.00000 time= 0.42548
Epoch: 0010 train_loss= 0.68273 train_acc= 1.00000 val_loss= 0.54555 val_acc= 1.00000 time= 0.40703
Epoch: 0011 train_loss= 0.67995 train_acc= 0.99609 val_loss= 0.55361 val_acc= 1.00000 time= 0.41361
Epoch: 0012 train_loss= 0.68800 train_acc= 1.00000 val_loss= 0.60293 val_acc= 1.00000 time= 0.41389
Epoch: 0013 train_loss= 0.68254 train_acc= 0.99609 val_loss= 0.61172 val_acc= 1.00000 time= 0.40675
Epoch: 0014 train_loss= 0.67982 train_acc= 0.99609 val_loss= 0.60989 val_acc= 1.00000 time= 0.42837
Epoch: 0015 train_loss= 0.67713 train_acc= 0.99609 val_loss= 0.60820 val_acc= 1.00000 time= 0.43122
Epoch: 0016 train_loss= 0.68515 train_acc= 1.00000 val_loss= 0.60652 val_acc= 1.00000 time= 0.41429
Epoch: 0017 train_loss= 0.68513 train_acc= 0.99609 val_loss= 0.60454 val_acc= 1.00000 time= 0.40979
Epoch: 0018 train_loss= 0.68241 train_acc= 0.99609 val_loss= 0.61917 val_acc= 1.00000 time= 0.40861
Epoch: 0019 train_loss= 0.68781 train_acc= 1.00000 val_loss= 0.61865 val_acc= 1.00000 time= 0.40888
Epoch: 0020 train_loss= 0.68239 train_acc= 1.00000 val_loss= 0.61443 val_acc= 1.00000 time= 0.41888
Epoch: 0021 train_loss= 0.67701 train_acc= 1.00000 val_loss= 0.61170 val_acc= 1.00000 time= 0.41368
Epoch: 0022 train_loss= 0.68508 train_acc= 0.99609 val_loss= 0.60998 val_acc= 1.00000 time= 0.41467
Epoch: 0023 train_loss= 0.68507 train_acc= 1.00000 val_loss= 0.60868 val_acc= 1.00000 time= 0.40898
Epoch: 0024 train_loss= 0.68507 train_acc= 1.00000 val_loss= 0.60696 val_acc= 1.00000 time= 0.40942
Epoch: 0025 train_loss= 0.68777 train_acc= 0.99609 val_loss= 0.60598 val_acc= 1.00000 time= 0.41051
Epoch: 0026 train_loss= 0.68235 train_acc= 1.00000 val_loss= 0.60475 val_acc= 1.00000 time= 0.43073
Epoch: 0027 train_loss= 0.68506 train_acc= 0.99609 val_loss= 0.60337 val_acc= 1.00000 time= 0.41290
Epoch: 0028 train_loss= 0.67695 train_acc= 1.00000 val_loss= 0.60252 val_acc= 1.00000 time= 0.41041
Epoch: 0029 train_loss= 0.68506 train_acc= 1.00000 val_loss= 0.60135 val_acc= 1.00000 time= 0.40647
Epoch: 0030 train_loss= 0.68505 train_acc= 1.00000 val_loss= 0.60060 val_acc= 1.00000 time= 0.40749
Epoch: 0031 train_loss= 0.68235 train_acc= 0.99609 val_loss= 0.60000 val_acc= 1.00000 time= 0.41397
Epoch: 0032 train_loss= 0.67698 train_acc= 1.00000 val_loss= 0.59949 val_acc= 1.00000 time= 0.41355
rank1 = 5 rank0 = 5 cost= 0.59959 accuracy= 0.99950 training time per epoch= 0.43147
F1-Score of non-Frauds: 0.999750
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499875
Epoch: 0001 train_loss= 0.69349 train_acc= 1.00000 val_loss= 0.69013 val_acc= 1.00000 time= 0.51790
Epoch: 0002 train_loss= 0.67981 train_acc= 0.99609 val_loss= 0.64521 val_acc= 1.00000 time= 0.41394
Epoch: 0003 train_loss= 0.68158 train_acc= 0.99609 val_loss= 0.63364 val_acc= 1.00000 time= 0.42254
Epoch: 0004 train_loss= 0.67394 train_acc= 1.00000 val_loss= 0.62699 val_acc= 1.00000 time= 0.42604
Epoch: 0005 train_loss= 0.66855 train_acc= 0.99219 val_loss= 0.62287 val_acc= 1.00000 time= 0.42055
Epoch: 0006 train_loss= 0.68074 train_acc= 0.99609 val_loss= 0.61910 val_acc= 1.00000 time= 0.40272
Epoch: 0007 train_loss= 0.67272 train_acc= 1.00000 val_loss= 0.61563 val_acc= 1.00000 time= 0.40721
Epoch: 0008 train_loss= 0.67539 train_acc= 1.00000 val_loss= 0.61165 val_acc= 1.00000 time= 0.40057
Epoch: 0009 train_loss= 0.67499 train_acc= 0.99609 val_loss= 0.60743 val_acc= 1.00000 time= 0.41830
Epoch: 0010 train_loss= 0.67507 train_acc= 0.99219 val_loss= 0.60375 val_acc= 1.00000 time= 0.41493
Epoch: 0011 train_loss= 0.67469 train_acc= 0.99609 val_loss= 0.60214 val_acc= 1.00000 time= 0.42846
Epoch: 0012 train_loss= 0.68200 train_acc= 0.98828 val_loss= 0.60182 val_acc= 1.00000 time= 0.41633
Epoch: 0013 train_loss= 0.67462 train_acc= 0.99609 val_loss= 0.60031 val_acc= 1.00000 time= 0.43103
Epoch: 0014 train_loss= 0.66944 train_acc= 1.00000 val_loss= 0.59764 val_acc= 1.00000 time= 0.42284
Epoch: 0015 train_loss= 0.67198 train_acc= 1.00000 val_loss= 0.59524 val_acc= 1.00000 time= 0.41753
Epoch: 0016 train_loss= 0.67717 train_acc= 0.99609 val_loss= 0.59264 val_acc= 1.00000 time= 0.44404
Epoch: 0017 train_loss= 0.66927 train_acc= 0.99609 val_loss= 0.58999 val_acc= 1.00000 time= 0.40464
Epoch: 0018 train_loss= 0.66903 train_acc= 1.00000 val_loss= 0.58808 val_acc= 1.00000 time= 0.41546
Epoch: 0019 train_loss= 0.67443 train_acc= 0.99609 val_loss= 0.58653 val_acc= 1.00000 time= 0.40066
Epoch: 0020 train_loss= 0.66917 train_acc= 1.00000 val_loss= 0.58512 val_acc= 1.00000 time= 0.40937
Epoch: 0021 train_loss= 0.67438 train_acc= 1.00000 val_loss= 0.58440 val_acc= 1.00000 time= 0.41486
Epoch: 0022 train_loss= 0.66911 train_acc= 1.00000 val_loss= 0.58247 val_acc= 1.00000 time= 0.39953
Epoch: 0023 train_loss= 0.67439 train_acc= 0.99609 val_loss= 0.56887 val_acc= 1.00000 time= 0.42055
Epoch: 0024 train_loss= 0.67159 train_acc= 1.00000 val_loss= 0.56029 val_acc= 1.00000 time= 0.43571
Epoch: 0025 train_loss= 0.67167 train_acc= 1.00000 val_loss= 0.55975 val_acc= 1.00000 time= 0.40709
Epoch: 0026 train_loss= 0.67165 train_acc= 1.00000 val_loss= 0.55826 val_acc= 1.00000 time= 0.40317
Epoch: 0027 train_loss= 0.67162 train_acc= 1.00000 val_loss= 0.56570 val_acc= 1.00000 time= 0.40388
Epoch: 0028 train_loss= 0.67432 train_acc= 1.00000 val_loss= 0.56713 val_acc= 1.00000 time= 0.40311
Epoch: 0029 train_loss= 0.67710 train_acc= 1.00000 val_loss= 0.56850 val_acc= 1.00000 time= 0.40215
Epoch: 0030 train_loss= 0.67159 train_acc= 0.99609 val_loss= 0.56670 val_acc= 1.00000 time= 0.40894
Epoch: 0031 train_loss= 0.70190 train_acc= 0.99219 val_loss= 0.56557 val_acc= 1.00000 time= 0.40801
Epoch: 0032 train_loss= 0.67701 train_acc= 0.99609 val_loss= 0.56866 val_acc= 1.00000 time= 0.40554
Epoch: 0033 train_loss= 0.66626 train_acc= 0.99609 val_loss= 0.56601 val_acc= 1.00000 time= 0.41245
Epoch: 0034 train_loss= 0.67165 train_acc= 1.00000 val_loss= 0.56413 val_acc= 1.00000 time= 0.42165
Epoch: 0035 train_loss= 0.67167 train_acc= 1.00000 val_loss= 0.56193 val_acc= 1.00000 time= 0.39942
Epoch: 0036 train_loss= 0.67431 train_acc= 0.99609 val_loss= 0.55967 val_acc= 1.00000 time= 0.43781
Epoch: 0037 train_loss= 0.66903 train_acc= 1.00000 val_loss= 0.57267 val_acc= 1.00000 time= 0.40032
Epoch: 0038 train_loss= 0.66387 train_acc= 0.99609 val_loss= 0.57862 val_acc= 1.00000 time= 0.42385
Epoch: 0039 train_loss= 0.67430 train_acc= 0.99219 val_loss= 0.57818 val_acc= 1.00000 time= 0.43315
Epoch: 0040 train_loss= 0.66912 train_acc= 0.99219 val_loss= 0.57494 val_acc= 1.00000 time= 0.42656
Epoch: 0041 train_loss= 0.66904 train_acc= 1.00000 val_loss= 0.57607 val_acc= 1.00000 time= 0.40808
Epoch: 0042 train_loss= 0.66943 train_acc= 1.00000 val_loss= 0.57936 val_acc= 1.00000 time= 0.43717
rank1 = 10 rank0 = 10 cost= 0.57949 accuracy= 0.99950 training time per epoch= 0.42808
F1-Score of non-Frauds: 0.999750
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499875
Epoch: 0001 train_loss= 0.63320 train_acc= 1.00000 val_loss= 0.52397 val_acc= 1.00000 time= 0.52117
Epoch: 0002 train_loss= 0.63688 train_acc= 1.00000 val_loss= 0.48331 val_acc= 1.00000 time= 0.42867
Epoch: 0003 train_loss= 0.63884 train_acc= 0.99609 val_loss= 0.46505 val_acc= 1.00000 time= 0.44272
Epoch: 0004 train_loss= 0.65984 train_acc= 0.99609 val_loss= 0.45569 val_acc= 1.00000 time= 0.43726
Epoch: 0005 train_loss= 0.64363 train_acc= 0.99609 val_loss= 0.45521 val_acc= 1.00000 time= 0.42757
Epoch: 0006 train_loss= 0.63568 train_acc= 0.99609 val_loss= 0.44496 val_acc= 1.00000 time= 0.41591
Epoch: 0007 train_loss= 0.64553 train_acc= 1.00000 val_loss= 0.43281 val_acc= 1.00000 time= 0.42707
Epoch: 0008 train_loss= 0.64545 train_acc= 0.99219 val_loss= 0.43127 val_acc= 1.00000 time= 0.40922
Epoch: 0009 train_loss= 0.64004 train_acc= 0.99609 val_loss= 0.43042 val_acc= 1.00000 time= 0.40727
Epoch: 0010 train_loss= 0.62998 train_acc= 1.00000 val_loss= 0.42658 val_acc= 1.00000 time= 0.40511
Epoch: 0011 train_loss= 0.65047 train_acc= 0.99609 val_loss= 0.41450 val_acc= 1.00000 time= 0.41996
Epoch: 0012 train_loss= 0.64771 train_acc= 1.00000 val_loss= 0.41299 val_acc= 1.00000 time= 0.40682
Epoch: 0013 train_loss= 0.63698 train_acc= 0.99609 val_loss= 0.40454 val_acc= 1.00000 time= 0.42571
Epoch: 0014 train_loss= 0.63690 train_acc= 1.00000 val_loss= 0.39527 val_acc= 1.00000 time= 0.42728
Epoch: 0015 train_loss= 0.62900 train_acc= 1.00000 val_loss= 0.40137 val_acc= 1.00000 time= 0.44520
Epoch: 0016 train_loss= 0.65028 train_acc= 1.00000 val_loss= 0.40241 val_acc= 1.00000 time= 0.40871
Epoch: 0017 train_loss= 0.65021 train_acc= 0.99609 val_loss= 0.40353 val_acc= 1.00000 time= 0.41074
Epoch: 0018 train_loss= 0.65288 train_acc= 0.99609 val_loss= 0.39502 val_acc= 1.00000 time= 0.42236
Epoch: 0019 train_loss= 0.63139 train_acc= 1.00000 val_loss= 0.39522 val_acc= 1.00000 time= 0.43004
Epoch: 0020 train_loss= 0.64477 train_acc= 1.00000 val_loss= 0.39151 val_acc= 1.00000 time= 0.43070
Epoch: 0021 train_loss= 0.63934 train_acc= 1.00000 val_loss= 0.38954 val_acc= 1.00000 time= 0.41910
Epoch: 0022 train_loss= 0.67072 train_acc= 0.99219 val_loss= 0.40313 val_acc= 1.00000 time= 0.42092
Epoch: 0023 train_loss= 0.63701 train_acc= 1.00000 val_loss= 0.43446 val_acc= 1.00000 time= 0.42373
Epoch: 0024 train_loss= 0.64482 train_acc= 0.99609 val_loss= 0.42919 val_acc= 1.00000 time= 0.42773
Epoch: 0025 train_loss= 0.63946 train_acc= 0.99609 val_loss= 0.41367 val_acc= 1.00000 time= 0.43573
Epoch: 0026 train_loss= 0.64740 train_acc= 1.00000 val_loss= 0.40925 val_acc= 1.00000 time= 0.43408
Epoch: 0027 train_loss= 0.63938 train_acc= 1.00000 val_loss= 0.41618 val_acc= 1.00000 time= 0.41269
Epoch: 0028 train_loss= 0.63676 train_acc= 0.99609 val_loss= 0.40687 val_acc= 1.00000 time= 0.40561
Epoch: 0029 train_loss= 0.63957 train_acc= 1.00000 val_loss= 0.39902 val_acc= 1.00000 time= 0.40864
Epoch: 0030 train_loss= 0.64477 train_acc= 0.99609 val_loss= 0.40434 val_acc= 1.00000 time= 0.40274
Epoch: 0031 train_loss= 0.64203 train_acc= 1.00000 val_loss= 0.39386 val_acc= 1.00000 time= 0.40631
Epoch: 0032 train_loss= 0.63670 train_acc= 1.00000 val_loss= 0.38458 val_acc= 1.00000 time= 0.41341
Epoch: 0033 train_loss= 0.63391 train_acc= 0.99609 val_loss= 0.40010 val_acc= 1.00000 time= 0.40850
Epoch: 0034 train_loss= 0.63433 train_acc= 1.00000 val_loss= 0.42216 val_acc= 1.00000 time= 0.41131
rank1 = 25 rank0 = 25 cost= 0.42248 accuracy= 0.99950 training time per epoch= 0.43582
F1-Score of non-Frauds: 0.999750
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499875
Epoch: 0001 train_loss= 0.60644 train_acc= 1.00000 val_loss= 0.44235 val_acc= 1.00000 time= 0.54573
Epoch: 0002 train_loss= 0.59028 train_acc= 1.00000 val_loss= 0.39951 val_acc= 1.00000 time= 0.43065
Epoch: 0003 train_loss= 0.58969 train_acc= 0.99609 val_loss= 0.36845 val_acc= 1.00000 time= 0.43324
Epoch: 0004 train_loss= 0.61067 train_acc= 1.00000 val_loss= 0.34525 val_acc= 1.00000 time= 0.41919
Epoch: 0005 train_loss= 0.61117 train_acc= 1.00000 val_loss= 0.32325 val_acc= 1.00000 time= 0.43771
Epoch: 0006 train_loss= 0.59299 train_acc= 1.00000 val_loss= 0.30733 val_acc= 1.00000 time= 0.42299
Epoch: 0007 train_loss= 0.59496 train_acc= 1.00000 val_loss= 0.29731 val_acc= 1.00000 time= 0.44426
Epoch: 0008 train_loss= 0.62441 train_acc= 0.99219 val_loss= 0.28592 val_acc= 1.00000 time= 0.42954
Epoch: 0009 train_loss= 0.59992 train_acc= 0.99609 val_loss= 0.28009 val_acc= 1.00000 time= 0.40901
Epoch: 0010 train_loss= 0.60506 train_acc= 1.00000 val_loss= 0.27040 val_acc= 1.00000 time= 0.42240
Epoch: 0011 train_loss= 0.60494 train_acc= 1.00000 val_loss= 0.26416 val_acc= 1.00000 time= 0.41266
Epoch: 0012 train_loss= 0.61565 train_acc= 0.99609 val_loss= 0.25835 val_acc= 1.00000 time= 0.41514
Epoch: 0013 train_loss= 0.60755 train_acc= 1.00000 val_loss= 0.25955 val_acc= 1.00000 time= 0.42068
Epoch: 0014 train_loss= 0.60219 train_acc= 0.99609 val_loss= 0.25890 val_acc= 1.00000 time= 0.41385
Epoch: 0015 train_loss= 0.59417 train_acc= 1.00000 val_loss= 0.25581 val_acc= 1.00000 time= 0.41139
Epoch: 0016 train_loss= 0.60213 train_acc= 1.00000 val_loss= 0.25287 val_acc= 1.00000 time= 0.42755
Epoch: 0017 train_loss= 0.57056 train_acc= 1.00000 val_loss= 0.25177 val_acc= 1.00000 time= 0.44196
Epoch: 0018 train_loss= 0.59665 train_acc= 0.99219 val_loss= 0.24719 val_acc= 1.00000 time= 0.44406
Epoch: 0019 train_loss= 0.59936 train_acc= 1.00000 val_loss= 0.24209 val_acc= 1.00000 time= 0.42462
Epoch: 0020 train_loss= 0.61281 train_acc= 1.00000 val_loss= 0.26412 val_acc= 1.00000 time= 0.44499
Epoch: 0021 train_loss= 0.60247 train_acc= 1.00000 val_loss= 0.27165 val_acc= 1.00000 time= 0.43507
Epoch: 0022 train_loss= 0.60722 train_acc= 1.00000 val_loss= 0.26063 val_acc= 1.00000 time= 0.45777
Epoch: 0023 train_loss= 0.59693 train_acc= 1.00000 val_loss= 0.25118 val_acc= 1.00000 time= 0.44302
Epoch: 0024 train_loss= 0.59096 train_acc= 1.00000 val_loss= 0.24141 val_acc= 1.00000 time= 0.44017
Epoch: 0025 train_loss= 0.58575 train_acc= 1.00000 val_loss= 0.23270 val_acc= 1.00000 time= 0.42737
Epoch: 0026 train_loss= 0.58600 train_acc= 1.00000 val_loss= 0.22505 val_acc= 1.00000 time= 0.43305
Epoch: 0027 train_loss= 0.59389 train_acc= 1.00000 val_loss= 0.22582 val_acc= 1.00000 time= 0.42764
Epoch: 0028 train_loss= 0.59638 train_acc= 1.00000 val_loss= 0.22528 val_acc= 1.00000 time= 0.44090
Epoch: 0029 train_loss= 0.59366 train_acc= 1.00000 val_loss= 0.22187 val_acc= 1.00000 time= 0.42566
Epoch: 0030 train_loss= 0.59126 train_acc= 1.00000 val_loss= 0.23177 val_acc= 1.00000 time= 0.43212
Epoch: 0031 train_loss= 0.59910 train_acc= 0.99609 val_loss= 0.22876 val_acc= 1.00000 time= 0.44846
Epoch: 0032 train_loss= 0.59377 train_acc= 1.00000 val_loss= 0.22852 val_acc= 1.00000 time= 0.44148
Epoch: 0033 train_loss= 0.60448 train_acc= 1.00000 val_loss= 0.22977 val_acc= 1.00000 time= 0.43811
Epoch: 0034 train_loss= 0.58292 train_acc= 1.00000 val_loss= 0.22672 val_acc= 1.00000 time= 0.43700
Epoch: 0035 train_loss= 0.58358 train_acc= 1.00000 val_loss= 0.23879 val_acc= 1.00000 time= 0.44842
Epoch: 0036 train_loss= 0.64322 train_acc= 0.99609 val_loss= 0.25194 val_acc= 1.00000 time= 0.43886
rank1 = 50 rank0 = 50 cost= 0.25256 accuracy= 0.99950 training time per epoch= 0.44768
F1-Score of non-Frauds: 0.999750
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499875
