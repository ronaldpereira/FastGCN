DATASET: amlsim_sample
Epoch: 0001 train_loss= 0.68739 train_acc= 0.99609 val_loss= 0.53382 val_acc= 1.00000 time= 0.53505
Epoch: 0002 train_loss= 0.67619 train_acc= 1.00000 val_loss= 0.53424 val_acc= 1.00000 time= 0.46775
Epoch: 0003 train_loss= 0.67859 train_acc= 1.00000 val_loss= 0.55317 val_acc= 1.00000 time= 0.45732
Epoch: 0004 train_loss= 0.67835 train_acc= 1.00000 val_loss= 0.55219 val_acc= 1.00000 time= 0.45542
Epoch: 0005 train_loss= 0.67814 train_acc= 1.00000 val_loss= 0.55082 val_acc= 1.00000 time= 0.44918
Epoch: 0006 train_loss= 0.68067 train_acc= 1.00000 val_loss= 0.54929 val_acc= 1.00000 time= 0.45750
Epoch: 0007 train_loss= 0.67782 train_acc= 1.00000 val_loss= 0.54728 val_acc= 1.00000 time= 0.46921
Epoch: 0008 train_loss= 0.68040 train_acc= 1.00000 val_loss= 0.54615 val_acc= 1.00000 time= 0.46401
Epoch: 0009 train_loss= 0.68571 train_acc= 1.00000 val_loss= 0.54408 val_acc= 1.00000 time= 0.47139
Epoch: 0010 train_loss= 0.68021 train_acc= 1.00000 val_loss= 0.56741 val_acc= 1.00000 time= 0.46482
Epoch: 0011 train_loss= 0.68284 train_acc= 0.99609 val_loss= 0.56687 val_acc= 1.00000 time= 0.45069
Epoch: 0012 train_loss= 0.68009 train_acc= 1.00000 val_loss= 0.56197 val_acc= 1.00000 time= 0.46651
Epoch: 0013 train_loss= 0.67191 train_acc= 0.99609 val_loss= 0.55738 val_acc= 1.00000 time= 0.46159
Epoch: 0014 train_loss= 0.67728 train_acc= 0.99609 val_loss= 0.55274 val_acc= 1.00000 time= 0.43992
Epoch: 0015 train_loss= 0.67995 train_acc= 0.99609 val_loss= 0.54785 val_acc= 1.00000 time= 0.45084
Epoch: 0016 train_loss= 0.67992 train_acc= 1.00000 val_loss= 0.54615 val_acc= 1.00000 time= 0.46876
Epoch: 0017 train_loss= 0.68261 train_acc= 0.99609 val_loss= 0.54384 val_acc= 1.00000 time= 0.44086
Epoch: 0018 train_loss= 0.66906 train_acc= 0.99609 val_loss= 0.54219 val_acc= 1.00000 time= 0.42739
Epoch: 0019 train_loss= 0.67174 train_acc= 1.00000 val_loss= 0.53909 val_acc= 1.00000 time= 0.42796
Epoch: 0020 train_loss= 0.67714 train_acc= 1.00000 val_loss= 0.53757 val_acc= 1.00000 time= 0.43873
Epoch: 0021 train_loss= 0.67714 train_acc= 1.00000 val_loss= 0.53624 val_acc= 1.00000 time= 0.44536
Epoch: 0022 train_loss= 0.67984 train_acc= 0.99609 val_loss= 0.53446 val_acc= 1.00000 time= 0.43194
Epoch: 0023 train_loss= 0.68253 train_acc= 1.00000 val_loss= 0.53273 val_acc= 1.00000 time= 0.43485
Epoch: 0024 train_loss= 0.67711 train_acc= 1.00000 val_loss= 0.55822 val_acc= 1.00000 time= 0.45034
Epoch: 0025 train_loss= 0.67712 train_acc= 0.99609 val_loss= 0.58433 val_acc= 1.00000 time= 0.46363
Epoch: 0026 train_loss= 0.68252 train_acc= 1.00000 val_loss= 0.59413 val_acc= 1.00000 time= 0.44452
Epoch: 0027 train_loss= 0.68251 train_acc= 0.99609 val_loss= 0.58010 val_acc= 1.00000 time= 0.44494
Epoch: 0028 train_loss= 0.67182 train_acc= 1.00000 val_loss= 0.56965 val_acc= 1.00000 time= 0.44441
Epoch: 0029 train_loss= 0.67711 train_acc= 1.00000 val_loss= 0.57701 val_acc= 1.00000 time= 0.43236
Epoch: 0030 train_loss= 0.67710 train_acc= 1.00000 val_loss= 0.56987 val_acc= 1.00000 time= 0.44784
Epoch: 0031 train_loss= 0.68250 train_acc= 0.99609 val_loss= 0.57563 val_acc= 1.00000 time= 0.45257
Epoch: 0032 train_loss= 0.68008 train_acc= 1.00000 val_loss= 0.63201 val_acc= 1.00000 time= 0.45275
rank1 = 5 rank0 = 5 cost= 0.63178 accuracy= 0.99950 training time per epoch= 0.46813
F1-Score of non-Frauds: 0.999750
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499875
Epoch: 0001 train_loss= 0.69489 train_acc= 1.00000 val_loss= 0.69183 val_acc= 1.00000 time= 0.54774
Epoch: 0002 train_loss= 0.66929 train_acc= 0.99609 val_loss= 0.64159 val_acc= 1.00000 time= 0.44171
Epoch: 0003 train_loss= 0.65646 train_acc= 0.99609 val_loss= 0.62626 val_acc= 1.00000 time= 0.44897
Epoch: 0004 train_loss= 0.67111 train_acc= 1.00000 val_loss= 0.61390 val_acc= 1.00000 time= 0.44939
Epoch: 0005 train_loss= 0.66632 train_acc= 0.99219 val_loss= 0.60566 val_acc= 1.00000 time= 0.45979
Epoch: 0006 train_loss= 0.64328 train_acc= 0.99609 val_loss= 0.59734 val_acc= 1.00000 time= 0.46319
Epoch: 0007 train_loss= 0.67011 train_acc= 1.00000 val_loss= 0.59012 val_acc= 1.00000 time= 0.45486
Epoch: 0008 train_loss= 0.64260 train_acc= 1.00000 val_loss= 0.58425 val_acc= 1.00000 time= 0.45005
Epoch: 0009 train_loss= 0.66064 train_acc= 0.99609 val_loss= 0.57923 val_acc= 1.00000 time= 0.46449
Epoch: 0010 train_loss= 0.67856 train_acc= 0.99219 val_loss= 0.57511 val_acc= 1.00000 time= 0.45564
Epoch: 0011 train_loss= 0.65936 train_acc= 0.99609 val_loss= 0.57218 val_acc= 1.00000 time= 0.43336
Epoch: 0012 train_loss= 0.65045 train_acc= 0.98828 val_loss= 0.56746 val_acc= 1.00000 time= 0.43313
Epoch: 0013 train_loss= 0.66993 train_acc= 0.99609 val_loss= 0.56483 val_acc= 1.00000 time= 0.42914
Epoch: 0014 train_loss= 0.65127 train_acc= 1.00000 val_loss= 0.56115 val_acc= 1.00000 time= 0.45464
Epoch: 0015 train_loss= 0.67721 train_acc= 1.00000 val_loss= 0.56037 val_acc= 1.00000 time= 0.46673
Epoch: 0016 train_loss= 0.66911 train_acc= 0.99609 val_loss= 0.55771 val_acc= 1.00000 time= 0.44280
Epoch: 0017 train_loss= 0.66659 train_acc= 0.99609 val_loss= 0.55353 val_acc= 1.00000 time= 0.44431
Epoch: 0018 train_loss= 0.66647 train_acc= 1.00000 val_loss= 0.55118 val_acc= 1.00000 time= 0.44728
Epoch: 0019 train_loss= 0.64874 train_acc= 0.99609 val_loss= 0.54761 val_acc= 1.00000 time= 0.47009
Epoch: 0020 train_loss= 0.66640 train_acc= 1.00000 val_loss= 0.54462 val_acc= 1.00000 time= 0.43963
Epoch: 0021 train_loss= 0.66382 train_acc= 1.00000 val_loss= 0.54210 val_acc= 1.00000 time= 0.45221
Epoch: 0022 train_loss= 0.66918 train_acc= 1.00000 val_loss= 0.54023 val_acc= 1.00000 time= 0.43483
Epoch: 0023 train_loss= 0.65391 train_acc= 0.99609 val_loss= 0.52878 val_acc= 1.00000 time= 0.46244
Epoch: 0024 train_loss= 0.65584 train_acc= 1.00000 val_loss= 0.51890 val_acc= 1.00000 time= 0.45717
Epoch: 0025 train_loss= 0.66921 train_acc= 1.00000 val_loss= 0.51240 val_acc= 1.00000 time= 0.47884
Epoch: 0026 train_loss= 0.67161 train_acc= 1.00000 val_loss= 0.50596 val_acc= 1.00000 time= 0.47927
Epoch: 0027 train_loss= 0.65818 train_acc= 1.00000 val_loss= 0.49893 val_acc= 1.00000 time= 0.45288
Epoch: 0028 train_loss= 0.66353 train_acc= 1.00000 val_loss= 0.49171 val_acc= 1.00000 time= 0.47138
Epoch: 0029 train_loss= 0.65619 train_acc= 1.00000 val_loss= 0.49340 val_acc= 1.00000 time= 0.45178
Epoch: 0030 train_loss= 0.66628 train_acc= 0.99609 val_loss= 0.50010 val_acc= 1.00000 time= 0.47310
Epoch: 0031 train_loss= 0.64505 train_acc= 0.99219 val_loss= 0.49773 val_acc= 1.00000 time= 0.46842
Epoch: 0032 train_loss= 0.67431 train_acc= 0.99609 val_loss= 0.49331 val_acc= 1.00000 time= 0.46186
Epoch: 0033 train_loss= 0.66081 train_acc= 0.99609 val_loss= 0.49670 val_acc= 1.00000 time= 0.45655
Epoch: 0034 train_loss= 0.65569 train_acc= 1.00000 val_loss= 0.49761 val_acc= 1.00000 time= 0.44540
Epoch: 0035 train_loss= 0.65840 train_acc= 1.00000 val_loss= 0.49964 val_acc= 1.00000 time= 0.45148
Epoch: 0036 train_loss= 0.65058 train_acc= 0.99609 val_loss= 0.50308 val_acc= 1.00000 time= 0.44708
Epoch: 0037 train_loss= 0.65825 train_acc= 1.00000 val_loss= 0.50661 val_acc= 1.00000 time= 0.43997
Epoch: 0038 train_loss= 0.66128 train_acc= 0.99609 val_loss= 0.50334 val_acc= 1.00000 time= 0.45300
Epoch: 0039 train_loss= 0.66103 train_acc= 0.99219 val_loss= 0.50469 val_acc= 1.00000 time= 0.44958
Epoch: 0040 train_loss= 0.66090 train_acc= 0.99219 val_loss= 0.50203 val_acc= 1.00000 time= 0.43879
Epoch: 0041 train_loss= 0.66080 train_acc= 1.00000 val_loss= 0.50190 val_acc= 1.00000 time= 0.43978
Epoch: 0042 train_loss= 0.64501 train_acc= 1.00000 val_loss= 0.49988 val_acc= 1.00000 time= 0.43465
Epoch: 0043 train_loss= 0.65287 train_acc= 1.00000 val_loss= 0.50013 val_acc= 1.00000 time= 0.43215
Epoch: 0044 train_loss= 0.67700 train_acc= 1.00000 val_loss= 0.49646 val_acc= 1.00000 time= 0.43762
Epoch: 0045 train_loss= 0.66618 train_acc= 1.00000 val_loss= 0.49821 val_acc= 1.00000 time= 0.43032
Epoch: 0046 train_loss= 0.67161 train_acc= 1.00000 val_loss= 0.49794 val_acc= 1.00000 time= 0.44281
Epoch: 0047 train_loss= 0.66905 train_acc= 1.00000 val_loss= 0.49823 val_acc= 1.00000 time= 0.44091
Epoch: 0048 train_loss= 0.66354 train_acc= 1.00000 val_loss= 0.49667 val_acc= 1.00000 time= 0.45938
Epoch: 0049 train_loss= 0.65819 train_acc= 1.00000 val_loss= 0.49353 val_acc= 1.00000 time= 0.46599
Epoch: 0050 train_loss= 0.65815 train_acc= 1.00000 val_loss= 0.49034 val_acc= 1.00000 time= 0.44757
Epoch: 0051 train_loss= 0.66619 train_acc= 0.99219 val_loss= 0.48748 val_acc= 1.00000 time= 0.45536
Epoch: 0052 train_loss= 0.65002 train_acc= 1.00000 val_loss= 0.48883 val_acc= 1.00000 time= 0.43847
Epoch: 0053 train_loss= 0.66618 train_acc= 1.00000 val_loss= 0.48596 val_acc= 1.00000 time= 0.43063
Epoch: 0054 train_loss= 0.65814 train_acc= 1.00000 val_loss= 0.48348 val_acc= 1.00000 time= 0.43119
Epoch: 0055 train_loss= 0.65578 train_acc= 0.99609 val_loss= 0.48797 val_acc= 1.00000 time= 0.44553
Epoch: 0056 train_loss= 0.65809 train_acc= 1.00000 val_loss= 0.48725 val_acc= 1.00000 time= 0.49525
Epoch: 0057 train_loss= 0.66623 train_acc= 1.00000 val_loss= 0.48450 val_acc= 1.00000 time= 0.45910
Epoch: 0058 train_loss= 0.70107 train_acc= 0.99609 val_loss= 0.48227 val_acc= 1.00000 time= 0.45086
Epoch: 0059 train_loss= 0.65536 train_acc= 1.00000 val_loss= 0.48631 val_acc= 1.00000 time= 0.46433
Epoch: 0060 train_loss= 0.67158 train_acc= 0.99609 val_loss= 0.48643 val_acc= 1.00000 time= 0.44407
Epoch: 0061 train_loss= 0.67163 train_acc= 0.99609 val_loss= 0.48428 val_acc= 1.00000 time= 0.45484
Epoch: 0062 train_loss= 0.67158 train_acc= 1.00000 val_loss= 0.48891 val_acc= 1.00000 time= 0.45263
Epoch: 0063 train_loss= 0.66095 train_acc= 1.00000 val_loss= 0.48914 val_acc= 1.00000 time= 0.44516
Epoch: 0064 train_loss= 0.64739 train_acc= 0.99609 val_loss= 0.48808 val_acc= 1.00000 time= 0.45310
Epoch: 0065 train_loss= 0.65812 train_acc= 0.99609 val_loss= 0.48992 val_acc= 1.00000 time= 0.44356
Epoch: 0066 train_loss= 0.66083 train_acc= 1.00000 val_loss= 0.48917 val_acc= 1.00000 time= 0.46880
Epoch: 0067 train_loss= 0.67162 train_acc= 1.00000 val_loss= 0.49481 val_acc= 1.00000 time= 0.45596
rank1 = 10 rank0 = 10 cost= 0.49420 accuracy= 0.99950 training time per epoch= 0.45987
F1-Score of non-Frauds: 0.999750
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499875
Epoch: 0001 train_loss= 0.62886 train_acc= 1.00000 val_loss= 0.51875 val_acc= 1.00000 time= 0.56501
Epoch: 0002 train_loss= 0.59915 train_acc= 1.00000 val_loss= 0.46676 val_acc= 1.00000 time= 0.44547
Epoch: 0003 train_loss= 0.63854 train_acc= 1.00000 val_loss= 0.42990 val_acc= 1.00000 time= 0.45001
Epoch: 0004 train_loss= 0.63562 train_acc= 0.99609 val_loss= 0.40499 val_acc= 1.00000 time= 0.44638
Epoch: 0005 train_loss= 0.60654 train_acc= 1.00000 val_loss= 0.38650 val_acc= 1.00000 time= 0.44984
Epoch: 0006 train_loss= 0.61485 train_acc= 1.00000 val_loss= 0.37390 val_acc= 1.00000 time= 0.43136
Epoch: 0007 train_loss= 0.61454 train_acc= 0.99219 val_loss= 0.36478 val_acc= 1.00000 time= 0.43631
Epoch: 0008 train_loss= 0.62782 train_acc= 0.99609 val_loss= 0.36157 val_acc= 1.00000 time= 0.43773
Epoch: 0009 train_loss= 0.61596 train_acc= 0.99609 val_loss= 0.35195 val_acc= 1.00000 time= 0.44927
Epoch: 0010 train_loss= 0.60673 train_acc= 1.00000 val_loss= 0.34506 val_acc= 1.00000 time= 0.45371
Epoch: 0011 train_loss= 0.63435 train_acc= 1.00000 val_loss= 0.33369 val_acc= 1.00000 time= 0.44407
Epoch: 0012 train_loss= 0.60256 train_acc= 1.00000 val_loss= 0.32636 val_acc= 1.00000 time= 0.47216
Epoch: 0013 train_loss= 0.61799 train_acc= 1.00000 val_loss= 0.32626 val_acc= 1.00000 time= 0.49288
Epoch: 0014 train_loss= 0.61827 train_acc= 1.00000 val_loss= 0.32525 val_acc= 1.00000 time= 0.48354
Epoch: 0015 train_loss= 0.62368 train_acc= 0.99609 val_loss= 0.31863 val_acc= 1.00000 time= 0.46060
Epoch: 0016 train_loss= 0.61255 train_acc= 1.00000 val_loss= 0.30774 val_acc= 1.00000 time= 0.47051
Epoch: 0017 train_loss= 0.63236 train_acc= 0.99219 val_loss= 0.30458 val_acc= 1.00000 time= 0.45081
Epoch: 0018 train_loss= 0.62094 train_acc= 1.00000 val_loss= 0.30238 val_acc= 1.00000 time= 0.47328
Epoch: 0019 train_loss= 0.61807 train_acc= 1.00000 val_loss= 0.31323 val_acc= 1.00000 time= 0.46751
Epoch: 0020 train_loss= 0.61835 train_acc= 1.00000 val_loss= 0.31862 val_acc= 1.00000 time= 0.44860
Epoch: 0021 train_loss= 0.61598 train_acc= 1.00000 val_loss= 0.31769 val_acc= 1.00000 time= 0.45215
Epoch: 0022 train_loss= 0.61521 train_acc= 0.99609 val_loss= 0.30771 val_acc= 1.00000 time= 0.45127
Epoch: 0023 train_loss= 0.62356 train_acc= 1.00000 val_loss= 0.30570 val_acc= 1.00000 time= 0.43788
Epoch: 0024 train_loss= 0.61545 train_acc= 1.00000 val_loss= 0.29810 val_acc= 1.00000 time= 0.44734
Epoch: 0025 train_loss= 0.62626 train_acc= 0.99609 val_loss= 0.30087 val_acc= 1.00000 time= 0.46118
Epoch: 0026 train_loss= 0.60261 train_acc= 1.00000 val_loss= 0.29302 val_acc= 1.00000 time= 0.44005
Epoch: 0027 train_loss= 0.63962 train_acc= 0.99609 val_loss= 0.29506 val_acc= 1.00000 time= 0.43981
Epoch: 0028 train_loss= 0.61592 train_acc= 0.99219 val_loss= 0.29731 val_acc= 1.00000 time= 0.44098
Epoch: 0029 train_loss= 0.59817 train_acc= 0.99609 val_loss= 0.30652 val_acc= 1.00000 time= 0.46774
Epoch: 0030 train_loss= 0.63766 train_acc= 0.99219 val_loss= 0.30407 val_acc= 1.00000 time= 0.48912
Epoch: 0031 train_loss= 0.61540 train_acc= 1.00000 val_loss= 0.31110 val_acc= 1.00000 time= 0.48803
Epoch: 0032 train_loss= 0.59956 train_acc= 1.00000 val_loss= 0.30842 val_acc= 1.00000 time= 0.46127
Epoch: 0033 train_loss= 0.60719 train_acc= 1.00000 val_loss= 0.32090 val_acc= 1.00000 time= 0.46092
Epoch: 0034 train_loss= 0.62312 train_acc= 0.99609 val_loss= 0.31678 val_acc= 1.00000 time= 0.45793
Epoch: 0035 train_loss= 0.63129 train_acc= 1.00000 val_loss= 0.31824 val_acc= 1.00000 time= 0.46599
Epoch: 0036 train_loss= 0.61910 train_acc= 1.00000 val_loss= 0.32560 val_acc= 1.00000 time= 0.49791
rank1 = 25 rank0 = 25 cost= 0.32480 accuracy= 0.99950 training time per epoch= 0.47405
F1-Score of non-Frauds: 0.999750
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499875
Epoch: 0001 train_loss= 0.58954 train_acc= 1.00000 val_loss= 0.44332 val_acc= 1.00000 time= 0.59371
Epoch: 0002 train_loss= 0.54693 train_acc= 1.00000 val_loss= 0.39329 val_acc= 1.00000 time= 0.45958
Epoch: 0003 train_loss= 0.56977 train_acc= 1.00000 val_loss= 0.35183 val_acc= 1.00000 time= 0.45230
Epoch: 0004 train_loss= 0.58399 train_acc= 0.99609 val_loss= 0.31882 val_acc= 1.00000 time= 0.45231
Epoch: 0005 train_loss= 0.53732 train_acc= 1.00000 val_loss= 0.29195 val_acc= 1.00000 time= 0.44655
Epoch: 0006 train_loss= 0.54655 train_acc= 0.99609 val_loss= 0.26968 val_acc= 1.00000 time= 0.45797
Epoch: 0007 train_loss= 0.56107 train_acc= 1.00000 val_loss= 0.25124 val_acc= 1.00000 time= 0.44533
Epoch: 0008 train_loss= 0.56378 train_acc= 1.00000 val_loss= 0.23451 val_acc= 1.00000 time= 0.44098
Epoch: 0009 train_loss= 0.56595 train_acc= 1.00000 val_loss= 0.22076 val_acc= 1.00000 time= 0.44807
Epoch: 0010 train_loss= 0.55815 train_acc= 1.00000 val_loss= 0.20632 val_acc= 1.00000 time= 0.44598
Epoch: 0011 train_loss= 0.53286 train_acc= 1.00000 val_loss= 0.19383 val_acc= 1.00000 time= 0.44338
Epoch: 0012 train_loss= 0.52969 train_acc= 0.99609 val_loss= 0.18610 val_acc= 1.00000 time= 0.45162
Epoch: 0013 train_loss= 0.54529 train_acc= 1.00000 val_loss= 0.17623 val_acc= 1.00000 time= 0.44658
Epoch: 0014 train_loss= 0.54699 train_acc= 0.99609 val_loss= 0.16477 val_acc= 1.00000 time= 0.44656
Epoch: 0015 train_loss= 0.54853 train_acc= 1.00000 val_loss= 0.15764 val_acc= 1.00000 time= 0.44541
Epoch: 0016 train_loss= 0.56827 train_acc= 1.00000 val_loss= 0.15034 val_acc= 1.00000 time= 0.44576
Epoch: 0017 train_loss= 0.56463 train_acc= 1.00000 val_loss= 0.15168 val_acc= 1.00000 time= 0.44799
Epoch: 0018 train_loss= 0.59553 train_acc= 0.99609 val_loss= 0.14646 val_acc= 1.00000 time= 0.45041
Epoch: 0019 train_loss= 0.51918 train_acc= 0.99609 val_loss= 0.14960 val_acc= 1.00000 time= 0.44157
Epoch: 0020 train_loss= 0.53573 train_acc= 1.00000 val_loss= 0.14715 val_acc= 1.00000 time= 0.45408
Epoch: 0021 train_loss= 0.58247 train_acc= 0.99219 val_loss= 0.14318 val_acc= 1.00000 time= 0.45310
Epoch: 0022 train_loss= 0.57239 train_acc= 1.00000 val_loss= 0.14254 val_acc= 1.00000 time= 0.45242
Epoch: 0023 train_loss= 0.56991 train_acc= 1.00000 val_loss= 0.14138 val_acc= 1.00000 time= 0.44338
Epoch: 0024 train_loss= 0.53636 train_acc= 1.00000 val_loss= 0.13940 val_acc= 1.00000 time= 0.44380
Epoch: 0025 train_loss= 0.56739 train_acc= 1.00000 val_loss= 0.13758 val_acc= 1.00000 time= 0.45316
Epoch: 0026 train_loss= 0.50407 train_acc= 1.00000 val_loss= 0.13296 val_acc= 1.00000 time= 0.44380
Epoch: 0027 train_loss= 0.54840 train_acc= 0.99609 val_loss= 0.12903 val_acc= 1.00000 time= 0.44343
Epoch: 0028 train_loss= 0.57241 train_acc= 1.00000 val_loss= 0.12683 val_acc= 1.00000 time= 0.44272
Epoch: 0029 train_loss= 0.54056 train_acc= 0.99609 val_loss= 0.12591 val_acc= 1.00000 time= 0.44218
Epoch: 0030 train_loss= 0.52702 train_acc= 1.00000 val_loss= 0.12138 val_acc= 1.00000 time= 0.45913
Epoch: 0031 train_loss= 0.54522 train_acc= 1.00000 val_loss= 0.11624 val_acc= 1.00000 time= 0.44903
Epoch: 0032 train_loss= 0.58860 train_acc= 0.99219 val_loss= 0.11317 val_acc= 1.00000 time= 0.45068
Epoch: 0033 train_loss= 0.56343 train_acc= 1.00000 val_loss= 0.11328 val_acc= 1.00000 time= 0.45898
Epoch: 0034 train_loss= 0.53596 train_acc= 0.99609 val_loss= 0.11476 val_acc= 1.00000 time= 0.46389
Epoch: 0035 train_loss= 0.52873 train_acc= 1.00000 val_loss= 0.11028 val_acc= 1.00000 time= 0.46381
Epoch: 0036 train_loss= 0.56690 train_acc= 0.99219 val_loss= 0.10998 val_acc= 1.00000 time= 0.46664
Epoch: 0037 train_loss= 0.52141 train_acc= 1.00000 val_loss= 0.10968 val_acc= 1.00000 time= 0.47130
Epoch: 0038 train_loss= 0.52918 train_acc= 0.99609 val_loss= 0.10903 val_acc= 1.00000 time= 0.45663
Epoch: 0039 train_loss= 0.55338 train_acc= 1.00000 val_loss= 0.10786 val_acc= 1.00000 time= 0.44953
Epoch: 0040 train_loss= 0.53793 train_acc= 1.00000 val_loss= 0.10584 val_acc= 1.00000 time= 0.44396
Epoch: 0041 train_loss= 0.57466 train_acc= 1.00000 val_loss= 0.10463 val_acc= 1.00000 time= 0.45886
Epoch: 0042 train_loss= 0.57102 train_acc= 0.99609 val_loss= 0.10571 val_acc= 1.00000 time= 0.44616
Epoch: 0043 train_loss= 0.52721 train_acc= 1.00000 val_loss= 0.11512 val_acc= 1.00000 time= 0.45238
Epoch: 0044 train_loss= 0.56430 train_acc= 1.00000 val_loss= 0.12042 val_acc= 1.00000 time= 0.45579
Epoch: 0045 train_loss= 0.51749 train_acc= 1.00000 val_loss= 0.11666 val_acc= 1.00000 time= 0.44697
Epoch: 0046 train_loss= 0.61584 train_acc= 0.99609 val_loss= 0.11003 val_acc= 1.00000 time= 0.44231
Epoch: 0047 train_loss= 0.56216 train_acc= 0.99609 val_loss= 0.10815 val_acc= 1.00000 time= 0.44694
Epoch: 0048 train_loss= 0.57443 train_acc= 0.99609 val_loss= 0.10998 val_acc= 1.00000 time= 0.44300
Epoch: 0049 train_loss= 0.53771 train_acc= 1.00000 val_loss= 0.10675 val_acc= 1.00000 time= 0.44785
Epoch: 0050 train_loss= 0.55347 train_acc= 1.00000 val_loss= 0.10060 val_acc= 1.00000 time= 0.44658
Epoch: 0051 train_loss= 0.55333 train_acc= 1.00000 val_loss= 0.09814 val_acc= 1.00000 time= 0.44249
Epoch: 0052 train_loss= 0.53715 train_acc= 0.99609 val_loss= 0.10296 val_acc= 1.00000 time= 0.44798
Epoch: 0053 train_loss= 0.56176 train_acc= 1.00000 val_loss= 0.10389 val_acc= 1.00000 time= 0.44321
Epoch: 0054 train_loss= 0.54539 train_acc= 0.99609 val_loss= 0.10769 val_acc= 1.00000 time= 0.45704
Epoch: 0055 train_loss= 0.54317 train_acc= 1.00000 val_loss= 0.11051 val_acc= 1.00000 time= 0.45433
Epoch: 0056 train_loss= 0.52080 train_acc= 0.99609 val_loss= 0.10917 val_acc= 1.00000 time= 0.45029
Epoch: 0057 train_loss= 0.54303 train_acc= 0.99609 val_loss= 0.10880 val_acc= 1.00000 time= 0.44064
Epoch: 0058 train_loss= 0.55912 train_acc= 1.00000 val_loss= 0.11156 val_acc= 1.00000 time= 0.44141
rank1 = 50 rank0 = 50 cost= 0.11154 accuracy= 0.99950 training time per epoch= 0.46032
F1-Score of non-Frauds: 0.999750
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499875
