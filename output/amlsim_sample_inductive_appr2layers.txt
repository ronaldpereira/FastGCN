DATASET: amlsim_sample
Epoch: 0001 train_loss= 0.68464 train_acc= 1.00000 val_loss= 0.60390 val_acc= 1.00000 time= 0.60778
Epoch: 0002 train_loss= 0.68425 train_acc= 1.00000 val_loss= 0.60364 val_acc= 1.00000 time= 0.52178
Epoch: 0003 train_loss= 0.68664 train_acc= 0.99609 val_loss= 0.59985 val_acc= 1.00000 time= 0.51957
Epoch: 0004 train_loss= 0.67569 train_acc= 0.99609 val_loss= 0.61459 val_acc= 1.00000 time= 0.50882
Epoch: 0005 train_loss= 0.68617 train_acc= 0.99609 val_loss= 0.62627 val_acc= 1.00000 time= 0.52782
Epoch: 0006 train_loss= 0.68870 train_acc= 0.99609 val_loss= 0.61313 val_acc= 1.00000 time= 0.54682
Epoch: 0007 train_loss= 0.68585 train_acc= 0.99609 val_loss= 0.60752 val_acc= 1.00000 time= 0.52494
Epoch: 0008 train_loss= 0.68302 train_acc= 1.00000 val_loss= 0.60396 val_acc= 1.00000 time= 0.53368
Epoch: 0009 train_loss= 0.68563 train_acc= 1.00000 val_loss= 0.60134 val_acc= 1.00000 time= 0.50973
Epoch: 0010 train_loss= 0.68285 train_acc= 1.00000 val_loss= 0.59849 val_acc= 1.00000 time= 0.52698
Epoch: 0011 train_loss= 0.68009 train_acc= 0.99609 val_loss= 0.59623 val_acc= 1.00000 time= 0.50008
Epoch: 0012 train_loss= 0.68003 train_acc= 1.00000 val_loss= 0.59452 val_acc= 1.00000 time= 0.53040
Epoch: 0013 train_loss= 0.68411 train_acc= 1.00000 val_loss= 0.66469 val_acc= 1.00000 time= 0.52401
Epoch: 0014 train_loss= 0.68266 train_acc= 0.99609 val_loss= 0.61635 val_acc= 1.00000 time= 0.51869
Epoch: 0015 train_loss= 0.67995 train_acc= 0.99609 val_loss= 0.60952 val_acc= 1.00000 time= 0.52904
Epoch: 0016 train_loss= 0.68262 train_acc= 1.00000 val_loss= 0.60734 val_acc= 1.00000 time= 0.52076
Epoch: 0017 train_loss= 0.68261 train_acc= 1.00000 val_loss= 0.61049 val_acc= 1.00000 time= 0.54630
Epoch: 0018 train_loss= 0.67998 train_acc= 0.99609 val_loss= 0.62756 val_acc= 1.00000 time= 0.54181
Epoch: 0019 train_loss= 0.68530 train_acc= 1.00000 val_loss= 0.61799 val_acc= 1.00000 time= 0.52863
Epoch: 0020 train_loss= 0.68258 train_acc= 1.00000 val_loss= 0.61303 val_acc= 1.00000 time= 0.51794
Epoch: 0021 train_loss= 0.68528 train_acc= 1.00000 val_loss= 0.61060 val_acc= 1.00000 time= 0.54154
Epoch: 0022 train_loss= 0.68527 train_acc= 0.99609 val_loss= 0.60806 val_acc= 1.00000 time= 0.52124
Epoch: 0023 train_loss= 0.68256 train_acc= 0.99609 val_loss= 0.61255 val_acc= 1.00000 time= 0.51589
Epoch: 0024 train_loss= 0.68530 train_acc= 1.00000 val_loss= 0.63847 val_acc= 1.00000 time= 0.54800
Epoch: 0025 train_loss= 0.67997 train_acc= 1.00000 val_loss= 0.62981 val_acc= 1.00000 time= 0.52799
Epoch: 0026 train_loss= 0.67717 train_acc= 1.00000 val_loss= 0.63428 val_acc= 1.00000 time= 0.49962
Epoch: 0027 train_loss= 0.67988 train_acc= 0.99609 val_loss= 0.61608 val_acc= 1.00000 time= 0.51379
Epoch: 0028 train_loss= 0.68255 train_acc= 1.00000 val_loss= 0.61212 val_acc= 1.00000 time= 0.52727
Epoch: 0029 train_loss= 0.68796 train_acc= 1.00000 val_loss= 0.60914 val_acc= 1.00000 time= 0.54275
Epoch: 0030 train_loss= 0.68525 train_acc= 1.00000 val_loss= 0.60698 val_acc= 1.00000 time= 0.53428
Epoch: 0031 train_loss= 0.67984 train_acc= 0.99609 val_loss= 0.60542 val_acc= 1.00000 time= 0.52165
Epoch: 0032 train_loss= 0.68254 train_acc= 1.00000 val_loss= 0.60372 val_acc= 1.00000 time= 0.54791
Epoch: 0033 train_loss= 0.68525 train_acc= 1.00000 val_loss= 0.60192 val_acc= 1.00000 time= 0.52514
Epoch: 0034 train_loss= 0.68255 train_acc= 1.00000 val_loss= 0.62213 val_acc= 1.00000 time= 0.50942
rank1 = 5 rank0 = 5 cost= 0.62227 accuracy= 0.99900 training time per epoch= 0.54437
F1-Score of non-Frauds: 0.999500
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499750
Epoch: 0001 train_loss= 0.68535 train_acc= 1.00000 val_loss= 0.67897 val_acc= 1.00000 time= 0.62710
Epoch: 0002 train_loss= 0.67697 train_acc= 1.00000 val_loss= 0.64174 val_acc= 1.00000 time= 0.51753
Epoch: 0003 train_loss= 0.67618 train_acc= 1.00000 val_loss= 0.63168 val_acc= 1.00000 time= 0.53552
Epoch: 0004 train_loss= 0.68185 train_acc= 0.99609 val_loss= 0.62541 val_acc= 1.00000 time= 0.50803
Epoch: 0005 train_loss= 0.66441 train_acc= 1.00000 val_loss= 0.62043 val_acc= 1.00000 time= 0.53973
Epoch: 0006 train_loss= 0.67571 train_acc= 1.00000 val_loss= 0.61600 val_acc= 1.00000 time= 0.52765
Epoch: 0007 train_loss= 0.67240 train_acc= 1.00000 val_loss= 0.61083 val_acc= 1.00000 time= 0.54074
Epoch: 0008 train_loss= 0.67761 train_acc= 1.00000 val_loss= 0.60694 val_acc= 1.00000 time= 0.53627
Epoch: 0009 train_loss= 0.67483 train_acc= 1.00000 val_loss= 0.60485 val_acc= 1.00000 time= 0.50437
Epoch: 0010 train_loss= 0.67999 train_acc= 0.99609 val_loss= 0.60269 val_acc= 1.00000 time= 0.54241
Epoch: 0011 train_loss= 0.67331 train_acc= 0.99609 val_loss= 0.59954 val_acc= 1.00000 time= 0.52110
Epoch: 0012 train_loss= 0.67479 train_acc= 1.00000 val_loss= 0.59794 val_acc= 1.00000 time= 0.53106
Epoch: 0013 train_loss= 0.66942 train_acc= 1.00000 val_loss= 0.59510 val_acc= 1.00000 time= 0.51380
Epoch: 0014 train_loss= 0.67980 train_acc= 0.99609 val_loss= 0.59237 val_acc= 1.00000 time= 0.53006
Epoch: 0015 train_loss= 0.67203 train_acc= 1.00000 val_loss= 0.58980 val_acc= 1.00000 time= 0.52316
Epoch: 0016 train_loss= 0.66915 train_acc= 1.00000 val_loss= 0.58987 val_acc= 1.00000 time= 0.53293
Epoch: 0017 train_loss= 0.66662 train_acc= 0.99609 val_loss= 0.58810 val_acc= 1.00000 time= 0.50893
Epoch: 0018 train_loss= 0.66912 train_acc= 1.00000 val_loss= 0.58655 val_acc= 1.00000 time= 0.54230
Epoch: 0019 train_loss= 0.67183 train_acc= 1.00000 val_loss= 0.58522 val_acc= 1.00000 time= 0.54962
Epoch: 0020 train_loss= 0.66901 train_acc= 1.00000 val_loss= 0.57797 val_acc= 1.00000 time= 0.51152
Epoch: 0021 train_loss= 0.67159 train_acc= 1.00000 val_loss= 0.54817 val_acc= 1.00000 time= 0.56418
Epoch: 0022 train_loss= 0.67700 train_acc= 1.00000 val_loss= 0.54786 val_acc= 1.00000 time= 0.51080
Epoch: 0023 train_loss= 0.66617 train_acc= 0.99219 val_loss= 0.54676 val_acc= 1.00000 time= 0.53057
Epoch: 0024 train_loss= 0.66893 train_acc= 0.99609 val_loss= 0.54436 val_acc= 1.00000 time= 0.49207
Epoch: 0025 train_loss= 0.67164 train_acc= 1.00000 val_loss= 0.54250 val_acc= 1.00000 time= 0.49664
Epoch: 0026 train_loss= 0.66893 train_acc= 1.00000 val_loss= 0.55462 val_acc= 1.00000 time= 0.52773
Epoch: 0027 train_loss= 0.66629 train_acc= 0.99609 val_loss= 0.55872 val_acc= 1.00000 time= 0.49238
Epoch: 0028 train_loss= 0.66627 train_acc= 1.00000 val_loss= 0.56103 val_acc= 1.00000 time= 0.45951
Epoch: 0029 train_loss= 0.67442 train_acc= 1.00000 val_loss= 0.56349 val_acc= 1.00000 time= 0.47356
Epoch: 0030 train_loss= 0.66633 train_acc= 1.00000 val_loss= 0.56582 val_acc= 1.00000 time= 0.48585
Epoch: 0031 train_loss= 0.66653 train_acc= 1.00000 val_loss= 0.56972 val_acc= 1.00000 time= 0.48532
Epoch: 0032 train_loss= 0.67704 train_acc= 1.00000 val_loss= 0.56654 val_acc= 1.00000 time= 0.48801
Epoch: 0033 train_loss= 0.67171 train_acc= 1.00000 val_loss= 0.57233 val_acc= 1.00000 time= 0.49818
Epoch: 0034 train_loss= 0.66650 train_acc= 1.00000 val_loss= 0.57005 val_acc= 1.00000 time= 0.49186
Epoch: 0035 train_loss= 0.67720 train_acc= 0.99219 val_loss= 0.56552 val_acc= 1.00000 time= 0.49332
Epoch: 0036 train_loss= 0.67167 train_acc= 1.00000 val_loss= 0.56456 val_acc= 1.00000 time= 0.49744
Epoch: 0037 train_loss= 0.67430 train_acc= 1.00000 val_loss= 0.56432 val_acc= 1.00000 time= 0.48589
Epoch: 0038 train_loss= 0.66889 train_acc= 1.00000 val_loss= 0.56634 val_acc= 1.00000 time= 0.48766
Epoch: 0039 train_loss= 0.66899 train_acc= 0.99609 val_loss= 0.56340 val_acc= 1.00000 time= 0.49063
Epoch: 0040 train_loss= 0.66649 train_acc= 1.00000 val_loss= 0.56051 val_acc= 1.00000 time= 0.49060
Epoch: 0041 train_loss= 0.66626 train_acc= 1.00000 val_loss= 0.55812 val_acc= 1.00000 time= 0.48241
Epoch: 0042 train_loss= 0.66893 train_acc= 1.00000 val_loss= 0.55608 val_acc= 1.00000 time= 0.50326
Epoch: 0043 train_loss= 0.67700 train_acc= 1.00000 val_loss= 0.55338 val_acc= 1.00000 time= 0.49660
Epoch: 0044 train_loss= 0.67704 train_acc= 1.00000 val_loss= 0.55130 val_acc= 1.00000 time= 0.48095
Epoch: 0045 train_loss= 0.67970 train_acc= 0.99609 val_loss= 0.54968 val_acc= 1.00000 time= 0.49948
Epoch: 0046 train_loss= 0.66891 train_acc= 1.00000 val_loss= 0.54835 val_acc= 1.00000 time= 0.48871
Epoch: 0047 train_loss= 0.67700 train_acc= 1.00000 val_loss= 0.57480 val_acc= 1.00000 time= 0.49391
rank1 = 10 rank0 = 10 cost= 0.57505 accuracy= 0.99900 training time per epoch= 0.52253
F1-Score of non-Frauds: 0.999500
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499750
Epoch: 0001 train_loss= 0.64031 train_acc= 0.99609 val_loss= 0.51267 val_acc= 1.00000 time= 0.60798
Epoch: 0002 train_loss= 0.63671 train_acc= 1.00000 val_loss= 0.47570 val_acc= 1.00000 time= 0.48416
Epoch: 0003 train_loss= 0.63345 train_acc= 1.00000 val_loss= 0.45877 val_acc= 1.00000 time= 0.50210
Epoch: 0004 train_loss= 0.64113 train_acc= 1.00000 val_loss= 0.44996 val_acc= 1.00000 time= 0.50315
Epoch: 0005 train_loss= 0.62530 train_acc= 1.00000 val_loss= 0.43506 val_acc= 1.00000 time= 0.49392
Epoch: 0006 train_loss= 0.67562 train_acc= 0.99609 val_loss= 0.43963 val_acc= 1.00000 time= 0.49706
Epoch: 0007 train_loss= 0.64563 train_acc= 0.99219 val_loss= 0.43085 val_acc= 1.00000 time= 0.51002
Epoch: 0008 train_loss= 0.63220 train_acc= 1.00000 val_loss= 0.41653 val_acc= 1.00000 time= 0.49855
Epoch: 0009 train_loss= 0.69200 train_acc= 0.99219 val_loss= 0.40518 val_acc= 1.00000 time= 0.50673
Epoch: 0010 train_loss= 0.65055 train_acc= 1.00000 val_loss= 0.41404 val_acc= 1.00000 time= 0.50478
Epoch: 0011 train_loss= 0.63711 train_acc= 1.00000 val_loss= 0.42304 val_acc= 1.00000 time= 0.50325
Epoch: 0012 train_loss= 0.63427 train_acc= 1.00000 val_loss= 0.43042 val_acc= 1.00000 time= 0.49456
Epoch: 0013 train_loss= 0.64761 train_acc= 0.99609 val_loss= 0.42641 val_acc= 1.00000 time= 0.48950
Epoch: 0014 train_loss= 0.63993 train_acc= 1.00000 val_loss= 0.42439 val_acc= 1.00000 time= 0.49560
Epoch: 0015 train_loss= 0.64239 train_acc= 1.00000 val_loss= 0.42085 val_acc= 1.00000 time= 0.49084
Epoch: 0016 train_loss= 0.64501 train_acc= 1.00000 val_loss= 0.41856 val_acc= 1.00000 time= 0.49194
Epoch: 0017 train_loss= 0.65308 train_acc= 0.99609 val_loss= 0.42324 val_acc= 1.00000 time= 0.49317
Epoch: 0018 train_loss= 0.64234 train_acc= 1.00000 val_loss= 0.42422 val_acc= 1.00000 time= 0.62095
Epoch: 0019 train_loss= 0.63133 train_acc= 0.99609 val_loss= 0.40754 val_acc= 1.00000 time= 0.64257
Epoch: 0020 train_loss= 0.64219 train_acc= 1.00000 val_loss= 0.41482 val_acc= 1.00000 time= 0.49664
Epoch: 0021 train_loss= 0.63931 train_acc= 0.99219 val_loss= 0.40814 val_acc= 1.00000 time= 0.49937
Epoch: 0022 train_loss= 0.64746 train_acc= 1.00000 val_loss= 0.40274 val_acc= 1.00000 time= 0.49170
Epoch: 0023 train_loss= 0.64218 train_acc= 1.00000 val_loss= 0.42377 val_acc= 1.00000 time= 0.51091
Epoch: 0024 train_loss= 0.64494 train_acc= 0.99609 val_loss= 0.42873 val_acc= 1.00000 time= 0.49003
Epoch: 0025 train_loss= 0.62348 train_acc= 1.00000 val_loss= 0.42732 val_acc= 1.00000 time= 0.49494
Epoch: 0026 train_loss= 0.65552 train_acc= 0.99609 val_loss= 0.41837 val_acc= 1.00000 time= 0.49105
Epoch: 0027 train_loss= 0.64481 train_acc= 0.98438 val_loss= 0.41363 val_acc= 1.00000 time= 0.48574
Epoch: 0028 train_loss= 0.65281 train_acc= 1.00000 val_loss= 0.41054 val_acc= 1.00000 time= 0.49038
Epoch: 0029 train_loss= 0.64507 train_acc= 1.00000 val_loss= 0.41702 val_acc= 1.00000 time= 0.49244
Epoch: 0030 train_loss= 0.63680 train_acc= 1.00000 val_loss= 0.40692 val_acc= 1.00000 time= 0.50264
Epoch: 0031 train_loss= 0.61814 train_acc= 0.99609 val_loss= 0.39525 val_acc= 1.00000 time= 0.48932
Epoch: 0032 train_loss= 0.63942 train_acc= 1.00000 val_loss= 0.38483 val_acc= 1.00000 time= 0.49645
Epoch: 0033 train_loss= 0.65277 train_acc= 1.00000 val_loss= 0.37875 val_acc= 1.00000 time= 0.49669
Epoch: 0034 train_loss= 0.64216 train_acc= 1.00000 val_loss= 0.37767 val_acc= 1.00000 time= 0.52171
Epoch: 0035 train_loss= 0.63962 train_acc= 1.00000 val_loss= 0.40247 val_acc= 1.00000 time= 0.50479
Epoch: 0036 train_loss= 0.65546 train_acc= 1.00000 val_loss= 0.39453 val_acc= 1.00000 time= 0.56835
Epoch: 0037 train_loss= 0.65007 train_acc= 0.99609 val_loss= 0.40216 val_acc= 1.00000 time= 0.52133
Epoch: 0038 train_loss= 0.63413 train_acc= 1.00000 val_loss= 0.40224 val_acc= 1.00000 time= 0.49960
Epoch: 0039 train_loss= 0.64478 train_acc= 0.99609 val_loss= 0.42343 val_acc= 1.00000 time= 0.52668
rank1 = 25 rank0 = 25 cost= 0.42407 accuracy= 0.99900 training time per epoch= 0.52380
F1-Score of non-Frauds: 0.999500
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499750
Epoch: 0001 train_loss= 0.59437 train_acc= 1.00000 val_loss= 0.43473 val_acc= 1.00000 time= 0.61760
Epoch: 0002 train_loss= 0.58516 train_acc= 1.00000 val_loss= 0.38450 val_acc= 1.00000 time= 0.51611
Epoch: 0003 train_loss= 0.58653 train_acc= 1.00000 val_loss= 0.35235 val_acc= 1.00000 time= 0.51347
Epoch: 0004 train_loss= 0.59877 train_acc= 1.00000 val_loss= 0.32520 val_acc= 1.00000 time= 0.51108
Epoch: 0005 train_loss= 0.60828 train_acc= 0.99609 val_loss= 0.30484 val_acc= 1.00000 time= 0.51993
Epoch: 0006 train_loss= 0.59256 train_acc= 0.99219 val_loss= 0.29341 val_acc= 1.00000 time= 0.51901
Epoch: 0007 train_loss= 0.59969 train_acc= 1.00000 val_loss= 0.28158 val_acc= 1.00000 time= 0.53267
Epoch: 0008 train_loss= 0.59702 train_acc= 0.99609 val_loss= 0.27952 val_acc= 1.00000 time= 0.51595
Epoch: 0009 train_loss= 0.61287 train_acc= 1.00000 val_loss= 0.28138 val_acc= 1.00000 time= 0.52065
Epoch: 0010 train_loss= 0.62501 train_acc= 0.99609 val_loss= 0.27238 val_acc= 1.00000 time= 0.51686
Epoch: 0011 train_loss= 0.57896 train_acc= 1.00000 val_loss= 0.27229 val_acc= 1.00000 time= 0.56765
Epoch: 0012 train_loss= 0.59160 train_acc= 1.00000 val_loss= 0.26537 val_acc= 1.00000 time= 0.50680
Epoch: 0013 train_loss= 0.59454 train_acc= 1.00000 val_loss= 0.25289 val_acc= 1.00000 time= 0.50196
Epoch: 0014 train_loss= 0.60207 train_acc= 1.00000 val_loss= 0.25712 val_acc= 1.00000 time= 0.53599
Epoch: 0015 train_loss= 0.60998 train_acc= 1.00000 val_loss= 0.25887 val_acc= 1.00000 time= 0.53191
Epoch: 0016 train_loss= 0.60462 train_acc= 1.00000 val_loss= 0.26750 val_acc= 1.00000 time= 0.52408
Epoch: 0017 train_loss= 0.57864 train_acc= 0.99609 val_loss= 0.25841 val_acc= 1.00000 time= 0.52392
Epoch: 0018 train_loss= 0.58908 train_acc= 1.00000 val_loss= 0.25553 val_acc= 1.00000 time= 0.52015
Epoch: 0019 train_loss= 0.57596 train_acc= 1.00000 val_loss= 0.26996 val_acc= 1.00000 time= 0.50724
Epoch: 0020 train_loss= 0.60190 train_acc= 1.00000 val_loss= 0.27827 val_acc= 1.00000 time= 0.52444
Epoch: 0021 train_loss= 0.60715 train_acc= 1.00000 val_loss= 0.26304 val_acc= 1.00000 time= 0.51036
Epoch: 0022 train_loss= 0.59661 train_acc= 0.99609 val_loss= 0.25672 val_acc= 1.00000 time= 0.49719
Epoch: 0023 train_loss= 0.58118 train_acc= 0.99609 val_loss= 0.26452 val_acc= 1.00000 time= 0.53436
Epoch: 0024 train_loss= 0.58347 train_acc= 1.00000 val_loss= 0.26224 val_acc= 1.00000 time= 0.50887
Epoch: 0025 train_loss= 0.58866 train_acc= 1.00000 val_loss= 0.25216 val_acc= 1.00000 time= 0.50470
Epoch: 0026 train_loss= 0.59915 train_acc= 0.99609 val_loss= 0.24725 val_acc= 1.00000 time= 0.54455
Epoch: 0027 train_loss= 0.60454 train_acc= 1.00000 val_loss= 0.23929 val_acc= 1.00000 time= 0.50345
Epoch: 0028 train_loss= 0.59372 train_acc= 1.00000 val_loss= 0.23729 val_acc= 1.00000 time= 0.49678
Epoch: 0029 train_loss= 0.60466 train_acc= 1.00000 val_loss= 0.23536 val_acc= 1.00000 time= 0.53549
Epoch: 0030 train_loss= 0.60178 train_acc= 1.00000 val_loss= 0.23586 val_acc= 1.00000 time= 0.51872
Epoch: 0031 train_loss= 0.60714 train_acc= 1.00000 val_loss= 0.23297 val_acc= 1.00000 time= 0.50769
Epoch: 0032 train_loss= 0.59112 train_acc= 0.99609 val_loss= 0.24335 val_acc= 1.00000 time= 0.54500
Epoch: 0033 train_loss= 0.61509 train_acc= 1.00000 val_loss= 0.24383 val_acc= 1.00000 time= 0.49795
Epoch: 0034 train_loss= 0.60215 train_acc= 1.00000 val_loss= 0.25644 val_acc= 1.00000 time= 0.50658
Epoch: 0035 train_loss= 0.59699 train_acc= 1.00000 val_loss= 0.26019 val_acc= 1.00000 time= 0.53695
Epoch: 0036 train_loss= 0.60768 train_acc= 0.99609 val_loss= 0.25356 val_acc= 1.00000 time= 0.51896
Epoch: 0037 train_loss= 0.59858 train_acc= 0.99609 val_loss= 0.25917 val_acc= 1.00000 time= 0.50530
rank1 = 50 rank0 = 50 cost= 0.26039 accuracy= 0.99900 training time per epoch= 0.53619
F1-Score of non-Frauds: 0.999500
F1-Score of Frauds: 0.000000
F1-Score macro: 0.499750
