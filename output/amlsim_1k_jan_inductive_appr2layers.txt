DATASET: amlsim_1k_jan
Epoch: 0001 train_loss= 0.68529 train_acc= 0.99609 val_loss= 0.60283 val_acc= 0.99200 time= 0.44892
Epoch: 0002 train_loss= 0.67638 train_acc= 0.98828 val_loss= 0.59750 val_acc= 0.99200 time= 0.35197
Epoch: 0003 train_loss= 0.67655 train_acc= 1.00000 val_loss= 0.59225 val_acc= 0.99200 time= 0.35393
Epoch: 0004 train_loss= 0.68401 train_acc= 0.98828 val_loss= 0.57990 val_acc= 0.99200 time= 0.35996
Epoch: 0005 train_loss= 0.66039 train_acc= 1.00000 val_loss= 0.57204 val_acc= 0.99200 time= 0.35454
Epoch: 0006 train_loss= 0.67831 train_acc= 0.98828 val_loss= 0.60301 val_acc= 0.99200 time= 0.35542
Epoch: 0007 train_loss= 0.67808 train_acc= 0.99609 val_loss= 0.59617 val_acc= 0.99200 time= 0.33763
Epoch: 0008 train_loss= 0.68088 train_acc= 0.99609 val_loss= 0.60526 val_acc= 0.99200 time= 0.33964
Epoch: 0009 train_loss= 0.67787 train_acc= 0.98047 val_loss= 0.60316 val_acc= 0.99200 time= 0.34175
Epoch: 0010 train_loss= 0.68601 train_acc= 0.99609 val_loss= 0.58268 val_acc= 0.99200 time= 0.33952
Epoch: 0011 train_loss= 0.65159 train_acc= 1.00000 val_loss= 0.57802 val_acc= 0.99200 time= 0.34746
Epoch: 0012 train_loss= 0.68301 train_acc= 0.99609 val_loss= 0.60376 val_acc= 0.99200 time= 0.35339
Epoch: 0013 train_loss= 0.67157 train_acc= 0.99219 val_loss= 0.60331 val_acc= 0.99200 time= 0.35353
Epoch: 0014 train_loss= 0.66957 train_acc= 1.00000 val_loss= 0.57601 val_acc= 0.99200 time= 0.35049
Epoch: 0015 train_loss= 0.67749 train_acc= 0.99609 val_loss= 0.57401 val_acc= 0.99200 time= 0.34425
Epoch: 0016 train_loss= 0.68550 train_acc= 0.99219 val_loss= 0.56400 val_acc= 0.99200 time= 0.34234
Epoch: 0017 train_loss= 0.68005 train_acc= 0.98047 val_loss= 0.55559 val_acc= 0.99200 time= 0.35521
Epoch: 0018 train_loss= 0.67461 train_acc= 0.99609 val_loss= 0.54985 val_acc= 0.99200 time= 0.36920
Epoch: 0019 train_loss= 0.68000 train_acc= 0.99219 val_loss= 0.54642 val_acc= 0.99200 time= 0.34015
Epoch: 0020 train_loss= 0.69776 train_acc= 0.99219 val_loss= 0.55992 val_acc= 0.99200 time= 0.36013
Epoch: 0021 train_loss= 0.67454 train_acc= 0.99609 val_loss= 0.56578 val_acc= 0.99200 time= 0.35269
Epoch: 0022 train_loss= 0.68536 train_acc= 0.98438 val_loss= 0.57085 val_acc= 0.99200 time= 0.34750
Epoch: 0023 train_loss= 0.67730 train_acc= 1.00000 val_loss= 0.56790 val_acc= 0.99200 time= 0.36920
Epoch: 0024 train_loss= 0.66645 train_acc= 0.99609 val_loss= 0.57222 val_acc= 0.99200 time= 0.35025
Epoch: 0025 train_loss= 0.67533 train_acc= 0.99219 val_loss= 0.58110 val_acc= 0.99200 time= 0.36070
Epoch: 0026 train_loss= 0.65603 train_acc= 0.98828 val_loss= 0.59540 val_acc= 0.99200 time= 0.35211
Epoch: 0027 train_loss= 0.65226 train_acc= 0.98438 val_loss= 0.61510 val_acc= 0.99200 time= 0.33856
Epoch: 0028 train_loss= 0.68260 train_acc= 0.98047 val_loss= 0.57953 val_acc= 0.99200 time= 0.34697
Epoch: 0029 train_loss= 0.68000 train_acc= 0.99219 val_loss= 0.58493 val_acc= 0.99200 time= 0.35201
Epoch: 0030 train_loss= 0.68529 train_acc= 0.99219 val_loss= 0.57740 val_acc= 0.99200 time= 0.35273
Epoch: 0031 train_loss= 0.67191 train_acc= 0.99219 val_loss= 0.57702 val_acc= 0.99200 time= 0.36026
Epoch: 0032 train_loss= 0.68799 train_acc= 0.99609 val_loss= 0.57039 val_acc= 0.99200 time= 0.34378
Epoch: 0033 train_loss= 0.68018 train_acc= 0.99219 val_loss= 0.57698 val_acc= 0.99200 time= 0.34428
Epoch: 0034 train_loss= 0.66911 train_acc= 0.99609 val_loss= 0.57264 val_acc= 0.99200 time= 0.34447
Epoch: 0035 train_loss= 0.67177 train_acc= 1.00000 val_loss= 0.57800 val_acc= 0.99200 time= 0.36253
Epoch: 0036 train_loss= 0.67510 train_acc= 0.98047 val_loss= 0.56790 val_acc= 0.99200 time= 0.34531
Epoch: 0037 train_loss= 0.66420 train_acc= 0.99219 val_loss= 0.55979 val_acc= 0.99200 time= 0.34141
Epoch: 0038 train_loss= 0.65858 train_acc= 0.99609 val_loss= 0.56130 val_acc= 0.99200 time= 0.34476
Epoch: 0039 train_loss= 0.66638 train_acc= 0.99609 val_loss= 0.56953 val_acc= 0.99200 time= 0.33982
Epoch: 0040 train_loss= 0.66121 train_acc= 0.98438 val_loss= 0.56840 val_acc= 0.99200 time= 0.35136
Epoch: 0041 train_loss= 0.65707 train_acc= 0.99609 val_loss= 0.56017 val_acc= 0.99200 time= 0.35553
Epoch: 0042 train_loss= 0.67177 train_acc= 0.99609 val_loss= 0.55854 val_acc= 0.99200 time= 0.34851
Epoch: 0043 train_loss= 0.67444 train_acc= 0.99609 val_loss= 0.55507 val_acc= 0.99200 time= 0.33666
Epoch: 0044 train_loss= 0.67448 train_acc= 1.00000 val_loss= 0.56845 val_acc= 0.99200 time= 0.34925
Epoch: 0045 train_loss= 0.66936 train_acc= 1.00000 val_loss= 0.61250 val_acc= 0.99200 time= 0.35563
rank1 = 5 rank0 = 5 cost= 0.61293 accuracy= 0.99506 training time per epoch= 0.36023
F1-Score of non-Frauds: 0.997525
F1-Score of Frauds: 0.000000
F1-Score macro: 0.498762
Epoch: 0001 train_loss= 0.71564 train_acc= 0.94141 val_loss= 0.71071 val_acc= 0.00800 time= 0.46578
Epoch: 0002 train_loss= 0.67245 train_acc= 0.98047 val_loss= 0.65528 val_acc= 0.99200 time= 0.36429
Epoch: 0003 train_loss= 0.65322 train_acc= 0.99219 val_loss= 0.63237 val_acc= 0.99200 time= 0.36928
Epoch: 0004 train_loss= 0.66478 train_acc= 1.00000 val_loss= 0.61825 val_acc= 0.99200 time= 0.36380
Epoch: 0005 train_loss= 0.65225 train_acc= 1.00000 val_loss= 0.60790 val_acc= 0.99200 time= 0.34053
Epoch: 0006 train_loss= 0.65083 train_acc= 0.98828 val_loss= 0.60025 val_acc= 0.99200 time= 0.34675
Epoch: 0007 train_loss= 0.66361 train_acc= 1.00000 val_loss= 0.59237 val_acc= 0.99200 time= 0.34397
Epoch: 0008 train_loss= 0.67023 train_acc= 1.00000 val_loss= 0.58594 val_acc= 0.99200 time= 0.35684
Epoch: 0009 train_loss= 0.67030 train_acc= 0.99609 val_loss= 0.57838 val_acc= 0.99200 time= 0.35311
Epoch: 0010 train_loss= 0.63983 train_acc= 1.00000 val_loss= 0.57201 val_acc= 0.99200 time= 0.34933
Epoch: 0011 train_loss= 0.65557 train_acc= 0.99219 val_loss= 0.56561 val_acc= 0.99200 time= 0.35089
Epoch: 0012 train_loss= 0.66271 train_acc= 1.00000 val_loss= 0.56085 val_acc= 0.99200 time= 0.34984
Epoch: 0013 train_loss= 0.66415 train_acc= 0.98828 val_loss= 0.55681 val_acc= 0.99200 time= 0.34747
Epoch: 0014 train_loss= 0.64490 train_acc= 0.99609 val_loss= 0.55256 val_acc= 0.99200 time= 0.35228
Epoch: 0015 train_loss= 0.64591 train_acc= 0.98047 val_loss= 0.54840 val_acc= 0.99200 time= 0.35727
Epoch: 0016 train_loss= 0.65965 train_acc= 0.98047 val_loss= 0.54372 val_acc= 0.99200 time= 0.35333
Epoch: 0017 train_loss= 0.65677 train_acc= 1.00000 val_loss= 0.54282 val_acc= 0.99200 time= 0.35408
Epoch: 0018 train_loss= 0.65393 train_acc= 0.99219 val_loss= 0.53882 val_acc= 0.99200 time= 0.34922
Epoch: 0019 train_loss= 0.66106 train_acc= 0.98047 val_loss= 0.53849 val_acc= 0.99200 time= 0.37580
Epoch: 0020 train_loss= 0.65259 train_acc= 1.00000 val_loss= 0.53829 val_acc= 0.99200 time= 0.37330
Epoch: 0021 train_loss= 0.67438 train_acc= 0.99219 val_loss= 0.53833 val_acc= 0.99200 time= 0.36091
Epoch: 0022 train_loss= 0.64588 train_acc= 1.00000 val_loss= 0.53440 val_acc= 0.99200 time= 0.34261
Epoch: 0023 train_loss= 0.66677 train_acc= 0.99219 val_loss= 0.53195 val_acc= 0.99200 time= 0.36203
Epoch: 0024 train_loss= 0.62281 train_acc= 0.99219 val_loss= 0.53005 val_acc= 0.99200 time= 0.35444
Epoch: 0025 train_loss= 0.68054 train_acc= 0.99219 val_loss= 0.52649 val_acc= 0.99200 time= 0.35589
Epoch: 0026 train_loss= 0.63597 train_acc= 0.98828 val_loss= 0.52727 val_acc= 0.99200 time= 0.36300
Epoch: 0027 train_loss= 0.64791 train_acc= 0.98828 val_loss= 0.52458 val_acc= 0.99200 time= 0.35432
Epoch: 0028 train_loss= 0.64377 train_acc= 0.99609 val_loss= 0.52177 val_acc= 0.99200 time= 0.35118
Epoch: 0029 train_loss= 0.63502 train_acc= 1.00000 val_loss= 0.51850 val_acc= 0.99200 time= 0.35880
Epoch: 0030 train_loss= 0.64095 train_acc= 0.99219 val_loss= 0.52187 val_acc= 0.99200 time= 0.35906
Epoch: 0031 train_loss= 0.65630 train_acc= 0.99219 val_loss= 0.52074 val_acc= 0.99200 time= 0.34886
Epoch: 0032 train_loss= 0.67964 train_acc= 0.99219 val_loss= 0.51922 val_acc= 0.99200 time= 0.35249
Epoch: 0033 train_loss= 0.65667 train_acc= 0.98828 val_loss= 0.52138 val_acc= 0.99200 time= 0.36115
Epoch: 0034 train_loss= 0.67956 train_acc= 0.98828 val_loss= 0.52010 val_acc= 0.99200 time= 0.35527
Epoch: 0035 train_loss= 0.65876 train_acc= 0.98828 val_loss= 0.51957 val_acc= 0.99200 time= 0.35957
Epoch: 0036 train_loss= 0.63466 train_acc= 0.98828 val_loss= 0.51822 val_acc= 0.99200 time= 0.36255
Epoch: 0037 train_loss= 0.66393 train_acc= 0.99219 val_loss= 0.51990 val_acc= 0.99200 time= 0.35290
Epoch: 0038 train_loss= 0.66186 train_acc= 0.99219 val_loss= 0.51689 val_acc= 0.99200 time= 0.35027
Epoch: 0039 train_loss= 0.66456 train_acc= 0.99609 val_loss= 0.51348 val_acc= 0.99200 time= 0.35075
Epoch: 0040 train_loss= 0.65096 train_acc= 0.99219 val_loss= 0.50952 val_acc= 0.99200 time= 0.35336
Epoch: 0041 train_loss= 0.66385 train_acc= 0.98828 val_loss= 0.50785 val_acc= 0.99200 time= 0.35193
Epoch: 0042 train_loss= 0.74055 train_acc= 0.98438 val_loss= 0.50598 val_acc= 0.99200 time= 0.35647
Epoch: 0043 train_loss= 0.66396 train_acc= 0.99219 val_loss= 0.51054 val_acc= 0.99200 time= 0.35438
Epoch: 0044 train_loss= 0.65601 train_acc= 0.99609 val_loss= 0.50965 val_acc= 0.99200 time= 0.35003
Epoch: 0045 train_loss= 0.64751 train_acc= 0.99609 val_loss= 0.50714 val_acc= 0.99200 time= 0.35203
Epoch: 0046 train_loss= 0.63958 train_acc= 1.00000 val_loss= 0.50651 val_acc= 0.99200 time= 0.34496
Epoch: 0047 train_loss= 0.64460 train_acc= 0.99219 val_loss= 0.50767 val_acc= 0.99200 time= 0.35487
Epoch: 0048 train_loss= 0.65018 train_acc= 0.98047 val_loss= 0.51058 val_acc= 0.99200 time= 0.36002
Epoch: 0049 train_loss= 0.64168 train_acc= 0.99219 val_loss= 0.51323 val_acc= 0.99200 time= 0.35996
Epoch: 0050 train_loss= 0.64581 train_acc= 1.00000 val_loss= 0.51038 val_acc= 0.99200 time= 0.36593
Epoch: 0051 train_loss= 0.64348 train_acc= 0.98828 val_loss= 0.51055 val_acc= 0.99200 time= 0.34862
Epoch: 0052 train_loss= 0.66638 train_acc= 1.00000 val_loss= 0.51700 val_acc= 0.99200 time= 0.34495
Epoch: 0053 train_loss= 0.65839 train_acc= 0.99219 val_loss= 0.51706 val_acc= 0.99200 time= 0.35352
rank1 = 10 rank0 = 10 cost= 0.51777 accuracy= 0.99506 training time per epoch= 0.36405
F1-Score of non-Frauds: 0.997525
F1-Score of Frauds: 0.000000
F1-Score macro: 0.498762
Epoch: 0001 train_loss= 0.61882 train_acc= 0.99219 val_loss= 0.54037 val_acc= 0.99200 time= 0.48201
Epoch: 0002 train_loss= 0.59122 train_acc= 1.00000 val_loss= 0.48759 val_acc= 0.99200 time= 0.36021
Epoch: 0003 train_loss= 0.61577 train_acc= 0.98828 val_loss= 0.45465 val_acc= 0.99200 time= 0.34501
Epoch: 0004 train_loss= 0.60889 train_acc= 0.99609 val_loss= 0.42759 val_acc= 0.99200 time= 0.36832
Epoch: 0005 train_loss= 0.60441 train_acc= 0.99609 val_loss= 0.40875 val_acc= 0.99200 time= 0.35513
Epoch: 0006 train_loss= 0.61927 train_acc= 1.00000 val_loss= 0.39531 val_acc= 0.99200 time= 0.35460
Epoch: 0007 train_loss= 0.57848 train_acc= 0.98828 val_loss= 0.38181 val_acc= 0.99200 time= 0.35485
Epoch: 0008 train_loss= 0.62015 train_acc= 0.99219 val_loss= 0.36418 val_acc= 0.99200 time= 0.35487
Epoch: 0009 train_loss= 0.62489 train_acc= 0.98828 val_loss= 0.34963 val_acc= 0.99200 time= 0.35890
Epoch: 0010 train_loss= 0.57648 train_acc= 0.98828 val_loss= 0.34378 val_acc= 0.99200 time= 0.37399
Epoch: 0011 train_loss= 0.55070 train_acc= 0.98828 val_loss= 0.33968 val_acc= 0.99200 time= 0.36199
Epoch: 0012 train_loss= 0.60969 train_acc= 0.99609 val_loss= 0.33547 val_acc= 0.99200 time= 0.35952
Epoch: 0013 train_loss= 0.58168 train_acc= 0.99609 val_loss= 0.32643 val_acc= 0.99200 time= 0.35061
Epoch: 0014 train_loss= 0.60289 train_acc= 1.00000 val_loss= 0.32297 val_acc= 0.99200 time= 0.36573
Epoch: 0015 train_loss= 0.58609 train_acc= 0.99609 val_loss= 0.32438 val_acc= 0.99200 time= 0.34899
Epoch: 0016 train_loss= 0.61891 train_acc= 0.99219 val_loss= 0.31908 val_acc= 0.99200 time= 0.37279
Epoch: 0017 train_loss= 0.64953 train_acc= 0.98438 val_loss= 0.31026 val_acc= 0.99200 time= 0.35144
Epoch: 0018 train_loss= 0.59841 train_acc= 0.99609 val_loss= 0.31163 val_acc= 0.99200 time= 0.34043
Epoch: 0019 train_loss= 0.58466 train_acc= 0.98828 val_loss= 0.30722 val_acc= 0.99200 time= 0.35882
Epoch: 0020 train_loss= 0.58151 train_acc= 0.99609 val_loss= 0.30736 val_acc= 0.99200 time= 0.35384
Epoch: 0021 train_loss= 0.60008 train_acc= 0.98828 val_loss= 0.30241 val_acc= 0.99200 time= 0.34200
Epoch: 0022 train_loss= 0.59458 train_acc= 1.00000 val_loss= 0.29789 val_acc= 0.99200 time= 0.34819
Epoch: 0023 train_loss= 0.57691 train_acc= 0.98438 val_loss= 0.30033 val_acc= 0.99200 time= 0.34084
Epoch: 0024 train_loss= 0.58175 train_acc= 0.99609 val_loss= 0.30918 val_acc= 0.99200 time= 0.34997
Epoch: 0025 train_loss= 0.57491 train_acc= 0.98828 val_loss= 0.30701 val_acc= 0.99200 time= 0.36274
Epoch: 0026 train_loss= 0.59875 train_acc= 0.99609 val_loss= 0.30910 val_acc= 0.99200 time= 0.35362
Epoch: 0027 train_loss= 0.58165 train_acc= 0.99219 val_loss= 0.31573 val_acc= 0.99200 time= 0.34494
Epoch: 0028 train_loss= 0.62739 train_acc= 1.00000 val_loss= 0.31087 val_acc= 0.99200 time= 0.34101
Epoch: 0029 train_loss= 0.66226 train_acc= 0.98438 val_loss= 0.30965 val_acc= 0.99200 time= 0.34742
Epoch: 0030 train_loss= 0.60310 train_acc= 0.98438 val_loss= 0.30804 val_acc= 0.99200 time= 0.34266
Epoch: 0031 train_loss= 0.59220 train_acc= 0.99219 val_loss= 0.30383 val_acc= 0.99200 time= 0.36573
Epoch: 0032 train_loss= 0.58929 train_acc= 0.99219 val_loss= 0.30511 val_acc= 0.99200 time= 0.38220
Epoch: 0033 train_loss= 0.60806 train_acc= 0.98047 val_loss= 0.30759 val_acc= 0.99200 time= 0.34397
Epoch: 0034 train_loss= 0.61036 train_acc= 1.00000 val_loss= 0.30209 val_acc= 0.99200 time= 0.35664
Epoch: 0035 train_loss= 0.59901 train_acc= 0.98828 val_loss= 0.29411 val_acc= 0.99200 time= 0.35045
Epoch: 0036 train_loss= 0.60565 train_acc= 0.98828 val_loss= 0.28718 val_acc= 0.99200 time= 0.34265
Epoch: 0037 train_loss= 0.57525 train_acc= 0.98828 val_loss= 0.28505 val_acc= 0.99200 time= 0.35431
Epoch: 0038 train_loss= 0.57406 train_acc= 0.98828 val_loss= 0.28861 val_acc= 0.99200 time= 0.36507
Epoch: 0039 train_loss= 0.59232 train_acc= 1.00000 val_loss= 0.29431 val_acc= 0.99200 time= 0.35282
Epoch: 0040 train_loss= 0.60590 train_acc= 0.99219 val_loss= 0.29836 val_acc= 0.99200 time= 0.34687
Epoch: 0041 train_loss= 0.61362 train_acc= 0.98438 val_loss= 0.29754 val_acc= 0.99200 time= 0.35475
Epoch: 0042 train_loss= 0.57154 train_acc= 1.00000 val_loss= 0.29927 val_acc= 0.99200 time= 0.35517
Epoch: 0043 train_loss= 0.61063 train_acc= 0.99219 val_loss= 0.29541 val_acc= 0.99200 time= 0.35630
Epoch: 0044 train_loss= 0.60238 train_acc= 0.99219 val_loss= 0.29173 val_acc= 0.99200 time= 0.34447
Epoch: 0045 train_loss= 0.60531 train_acc= 1.00000 val_loss= 0.28947 val_acc= 0.99200 time= 0.34220
Epoch: 0046 train_loss= 0.61062 train_acc= 0.98438 val_loss= 0.29095 val_acc= 0.99200 time= 0.35968
Epoch: 0047 train_loss= 0.60193 train_acc= 0.99219 val_loss= 0.28679 val_acc= 0.99200 time= 0.36728
Epoch: 0048 train_loss= 0.61561 train_acc= 0.99609 val_loss= 0.28261 val_acc= 0.99200 time= 0.36408
Epoch: 0049 train_loss= 0.58794 train_acc= 0.99219 val_loss= 0.27562 val_acc= 0.99200 time= 0.35974
Epoch: 0050 train_loss= 0.61254 train_acc= 0.99609 val_loss= 0.28364 val_acc= 0.99200 time= 0.36315
Epoch: 0051 train_loss= 0.61124 train_acc= 0.99609 val_loss= 0.28311 val_acc= 0.99200 time= 0.36006
Epoch: 0052 train_loss= 0.58338 train_acc= 0.99609 val_loss= 0.28385 val_acc= 0.99200 time= 0.34775
Epoch: 0053 train_loss= 0.59474 train_acc= 0.99219 val_loss= 0.29459 val_acc= 0.99200 time= 0.35441
Epoch: 0054 train_loss= 0.60159 train_acc= 0.99609 val_loss= 0.28999 val_acc= 0.99200 time= 0.37394
Epoch: 0055 train_loss= 0.59479 train_acc= 0.99609 val_loss= 0.28390 val_acc= 0.99200 time= 0.37307
Epoch: 0056 train_loss= 0.60849 train_acc= 0.99609 val_loss= 0.28301 val_acc= 0.99200 time= 0.34927
Epoch: 0057 train_loss= 0.60593 train_acc= 1.00000 val_loss= 0.28743 val_acc= 0.99200 time= 0.36193
Epoch: 0058 train_loss= 0.58403 train_acc= 0.99609 val_loss= 0.29157 val_acc= 0.99200 time= 0.35920
Epoch: 0059 train_loss= 0.59344 train_acc= 1.00000 val_loss= 0.28779 val_acc= 0.99200 time= 0.36351
Epoch: 0060 train_loss= 0.59595 train_acc= 0.99609 val_loss= 0.28825 val_acc= 0.99200 time= 0.35897
Epoch: 0061 train_loss= 0.64269 train_acc= 0.99219 val_loss= 0.28480 val_acc= 0.99200 time= 0.37237
Epoch: 0062 train_loss= 0.56268 train_acc= 1.00000 val_loss= 0.29353 val_acc= 0.99200 time= 0.34756
rank1 = 25 rank0 = 25 cost= 0.29319 accuracy= 0.99506 training time per epoch= 0.36399
F1-Score of non-Frauds: 0.997525
F1-Score of Frauds: 0.000000
F1-Score macro: 0.498762
Epoch: 0001 train_loss= 0.57887 train_acc= 0.99609 val_loss= 0.46578 val_acc= 0.99200 time= 0.47385
Epoch: 0002 train_loss= 0.57287 train_acc= 0.99219 val_loss= 0.42571 val_acc= 0.99200 time= 0.35672
Epoch: 0003 train_loss= 0.55438 train_acc= 0.99609 val_loss= 0.39055 val_acc= 0.99200 time= 0.34595
Epoch: 0004 train_loss= 0.56244 train_acc= 0.98828 val_loss= 0.35848 val_acc= 0.99200 time= 0.35997
Epoch: 0005 train_loss= 0.54975 train_acc= 0.99609 val_loss= 0.33376 val_acc= 0.99200 time= 0.34554
Epoch: 0006 train_loss= 0.57639 train_acc= 0.99219 val_loss= 0.31105 val_acc= 0.99200 time= 0.35535
Epoch: 0007 train_loss= 0.50801 train_acc= 0.99219 val_loss= 0.29063 val_acc= 0.99200 time= 0.34803
Epoch: 0008 train_loss= 0.53028 train_acc= 1.00000 val_loss= 0.26898 val_acc= 0.99200 time= 0.37061
Epoch: 0009 train_loss= 0.49963 train_acc= 1.00000 val_loss= 0.25283 val_acc= 0.99200 time= 0.36161
Epoch: 0010 train_loss= 0.53442 train_acc= 1.00000 val_loss= 0.24112 val_acc= 0.99200 time= 0.36230
Epoch: 0011 train_loss= 0.55463 train_acc= 0.99219 val_loss= 0.23149 val_acc= 0.99200 time= 0.36328
Epoch: 0012 train_loss= 0.50989 train_acc= 0.99219 val_loss= 0.22102 val_acc= 0.99200 time= 0.37599
Epoch: 0013 train_loss= 0.52157 train_acc= 1.00000 val_loss= 0.20957 val_acc= 0.99200 time= 0.35811
Epoch: 0014 train_loss= 0.55904 train_acc= 0.98828 val_loss= 0.20240 val_acc= 0.99200 time= 0.36461
Epoch: 0015 train_loss= 0.50358 train_acc= 0.98828 val_loss= 0.19622 val_acc= 0.99200 time= 0.36461
Epoch: 0016 train_loss= 0.51123 train_acc= 0.98828 val_loss= 0.18961 val_acc= 0.99200 time= 0.36461
Epoch: 0017 train_loss= 0.53450 train_acc= 0.99609 val_loss= 0.18209 val_acc= 0.99200 time= 0.37154
Epoch: 0018 train_loss= 0.53328 train_acc= 1.00000 val_loss= 0.17818 val_acc= 0.99200 time= 0.37849
Epoch: 0019 train_loss= 0.52639 train_acc= 0.99609 val_loss= 0.17493 val_acc= 0.99200 time= 0.36620
Epoch: 0020 train_loss= 0.52043 train_acc= 0.99219 val_loss= 0.17317 val_acc= 0.99200 time= 0.38439
Epoch: 0021 train_loss= 0.53420 train_acc= 0.99609 val_loss= 0.17147 val_acc= 0.99200 time= 0.36155
Epoch: 0022 train_loss= 0.57030 train_acc= 0.99609 val_loss= 0.16917 val_acc= 0.99200 time= 0.35742
Epoch: 0023 train_loss= 0.55580 train_acc= 0.99609 val_loss= 0.16826 val_acc= 0.99200 time= 0.37357
Epoch: 0024 train_loss= 0.45034 train_acc= 0.99609 val_loss= 0.17032 val_acc= 0.99200 time= 0.36544
Epoch: 0025 train_loss= 0.52053 train_acc= 0.99609 val_loss= 0.16666 val_acc= 0.99200 time= 0.36083
Epoch: 0026 train_loss= 0.50649 train_acc= 0.99609 val_loss= 0.16102 val_acc= 0.99200 time= 0.35516
Epoch: 0027 train_loss= 0.47661 train_acc= 0.98438 val_loss= 0.15668 val_acc= 0.99200 time= 0.36362
Epoch: 0028 train_loss= 0.62222 train_acc= 0.98438 val_loss= 0.15440 val_acc= 0.99200 time= 0.36684
Epoch: 0029 train_loss= 0.47972 train_acc= 0.98438 val_loss= 0.15444 val_acc= 0.99200 time= 0.37937
Epoch: 0030 train_loss= 0.54679 train_acc= 0.99219 val_loss= 0.15204 val_acc= 0.99200 time= 0.38100
Epoch: 0031 train_loss= 0.50239 train_acc= 0.99609 val_loss= 0.15189 val_acc= 0.99200 time= 0.36494
Epoch: 0032 train_loss= 0.52492 train_acc= 0.99219 val_loss= 0.15029 val_acc= 0.99200 time= 0.36464
Epoch: 0033 train_loss= 0.51672 train_acc= 0.99609 val_loss= 0.14479 val_acc= 0.99200 time= 0.37059
Epoch: 0034 train_loss= 0.51788 train_acc= 1.00000 val_loss= 0.14562 val_acc= 0.99200 time= 0.38621
Epoch: 0035 train_loss= 0.54995 train_acc= 0.98828 val_loss= 0.14287 val_acc= 0.99200 time= 0.36153
Epoch: 0036 train_loss= 0.49974 train_acc= 0.99609 val_loss= 0.14206 val_acc= 0.99200 time= 0.36289
Epoch: 0037 train_loss= 0.56398 train_acc= 0.98828 val_loss= 0.14643 val_acc= 0.99200 time= 0.36202
Epoch: 0038 train_loss= 0.51061 train_acc= 0.99609 val_loss= 0.14675 val_acc= 0.99200 time= 0.35330
Epoch: 0039 train_loss= 0.52483 train_acc= 0.98828 val_loss= 0.14711 val_acc= 0.99200 time= 0.37036
Epoch: 0040 train_loss= 0.51071 train_acc= 0.99219 val_loss= 0.14185 val_acc= 0.99200 time= 0.36836
Epoch: 0041 train_loss= 0.56223 train_acc= 0.99219 val_loss= 0.13995 val_acc= 0.99200 time= 0.34815
Epoch: 0042 train_loss= 0.47667 train_acc= 0.99609 val_loss= 0.14136 val_acc= 0.99200 time= 0.36435
Epoch: 0043 train_loss= 0.52120 train_acc= 1.00000 val_loss= 0.13840 val_acc= 0.99200 time= 0.36124
Epoch: 0044 train_loss= 0.49738 train_acc= 1.00000 val_loss= 0.13444 val_acc= 0.99200 time= 0.35640
Epoch: 0045 train_loss= 0.54154 train_acc= 0.98438 val_loss= 0.13431 val_acc= 0.99200 time= 0.36041
Epoch: 0046 train_loss= 0.51307 train_acc= 1.00000 val_loss= 0.13693 val_acc= 0.99200 time= 0.35560
Epoch: 0047 train_loss= 0.52568 train_acc= 0.99219 val_loss= 0.13761 val_acc= 0.99200 time= 0.34308
Epoch: 0048 train_loss= 0.54658 train_acc= 0.99609 val_loss= 0.13675 val_acc= 0.99200 time= 0.35979
Epoch: 0049 train_loss= 0.51850 train_acc= 0.99219 val_loss= 0.13139 val_acc= 0.99200 time= 0.37048
Epoch: 0050 train_loss= 0.49508 train_acc= 0.99609 val_loss= 0.12935 val_acc= 0.99200 time= 0.35756
Epoch: 0051 train_loss= 0.54258 train_acc= 0.99609 val_loss= 0.12857 val_acc= 0.99200 time= 0.36583
Epoch: 0052 train_loss= 0.48539 train_acc= 0.99609 val_loss= 0.12951 val_acc= 0.99200 time= 0.37631
Epoch: 0053 train_loss= 0.51593 train_acc= 1.00000 val_loss= 0.13467 val_acc= 0.99200 time= 0.36372
Epoch: 0054 train_loss= 0.50599 train_acc= 0.98438 val_loss= 0.13555 val_acc= 0.99200 time= 0.35208
Epoch: 0055 train_loss= 0.51580 train_acc= 0.98438 val_loss= 0.13973 val_acc= 0.99200 time= 0.36743
Epoch: 0056 train_loss= 0.54643 train_acc= 0.98828 val_loss= 0.13788 val_acc= 0.99200 time= 0.36785
Epoch: 0057 train_loss= 0.51927 train_acc= 0.98828 val_loss= 0.13486 val_acc= 0.99200 time= 0.36910
Epoch: 0058 train_loss= 0.48596 train_acc= 0.99219 val_loss= 0.13300 val_acc= 0.99200 time= 0.36223
Epoch: 0059 train_loss= 0.51400 train_acc= 0.99609 val_loss= 0.13561 val_acc= 0.99200 time= 0.36551
Epoch: 0060 train_loss= 0.57270 train_acc= 0.98828 val_loss= 0.13616 val_acc= 0.99200 time= 0.35710
Epoch: 0061 train_loss= 0.51029 train_acc= 0.99219 val_loss= 0.13191 val_acc= 0.99200 time= 0.37166
Epoch: 0062 train_loss= 0.59120 train_acc= 0.98828 val_loss= 0.13180 val_acc= 0.99200 time= 0.36167
Epoch: 0063 train_loss= 0.53201 train_acc= 0.99609 val_loss= 0.12919 val_acc= 0.99200 time= 0.37954
Epoch: 0064 train_loss= 0.56313 train_acc= 0.99219 val_loss= 0.12737 val_acc= 0.99200 time= 0.36072
Epoch: 0065 train_loss= 0.54205 train_acc= 0.99219 val_loss= 0.13073 val_acc= 0.99200 time= 0.36905
Epoch: 0066 train_loss= 0.49326 train_acc= 1.00000 val_loss= 0.13205 val_acc= 0.99200 time= 0.36486
Epoch: 0067 train_loss= 0.48705 train_acc= 0.99609 val_loss= 0.13036 val_acc= 0.99200 time= 0.36864
Epoch: 0068 train_loss= 0.53763 train_acc= 0.99219 val_loss= 0.13028 val_acc= 0.99200 time= 0.35477
Epoch: 0069 train_loss= 0.52234 train_acc= 0.99609 val_loss= 0.13131 val_acc= 0.99200 time= 0.36963
Epoch: 0070 train_loss= 0.52471 train_acc= 0.99609 val_loss= 0.13350 val_acc= 0.99200 time= 0.36077
Epoch: 0071 train_loss= 0.51102 train_acc= 1.00000 val_loss= 0.13312 val_acc= 0.99200 time= 0.36953
Epoch: 0072 train_loss= 0.49077 train_acc= 0.99609 val_loss= 0.13078 val_acc= 0.99200 time= 0.37570
Epoch: 0073 train_loss= 0.50657 train_acc= 0.99609 val_loss= 0.13183 val_acc= 0.99200 time= 0.36636
Epoch: 0074 train_loss= 0.52787 train_acc= 0.98828 val_loss= 0.13533 val_acc= 0.99200 time= 0.35242
rank1 = 50 rank0 = 50 cost= 0.13030 accuracy= 0.99506 training time per epoch= 0.37071
F1-Score of non-Frauds: 0.997525
F1-Score of Frauds: 0.000000
F1-Score macro: 0.498762
